{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC478 Machine Learning - Spring 2022\n",
    "\n",
    "## Instructor: Fereydoon Vafaei\n",
    "\n",
    "## <font color=\"blue\">Assignment-4: Multi-Class Classification and Regression with Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jacob Enoch YU11019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Assignment-4, you're going to perform multi-class classification and regression using Neural Networks in Tensorflow/Keras.\n",
    "\n",
    "Pedagogically, this assignment will help you:\n",
    "- better understand how neural networks are built and applied on ML tasks - specifically multi-class classification and regression.\n",
    "- practice NN implementation using Tensorflow 2 and Keras Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Course Policy Reminder</b>\n",
    "Debugging the codes and error resolution are always the students' responsbility. This policy will be enforced in email communications and the office hours. Keep in mind that all assignments are individual graded tasks. Any collaboration with other students is strictly prohibited and is considered as cheating. Students should NOT share any answer, solution, or code with other students. Violations of these policies would be penalized according to UMBC academic integrity policy.\n",
    "\n",
    "**You must run ALL cells** and get the correct outputs for all cells and give complete answers to all questions. **Cells/codes with no output get zero!**\n",
    "\n",
    "Follow the instructions for each step very carefully.\n",
    "\n",
    "Wherever needed, you should replace `...` elipsis with your code.\n",
    "\n",
    "`...` may indicate one or more lines of missing codes. Some outputs are provided to you to use as reference and to verify that your output is correct.\n",
    "\n",
    "**Preprocessing Effect on Grade**: Preprocessing steps are so critical in each part and you should pay special attention to make sure that you do all preprocessing steps correctly. That is why the reference outputs have been provided in preprocessing steps. Even though preprocessing steps have no direct positive points themselves, they have negative impact if you make mistakes in preprocessing, and your notebook would become unqualified for grading implementation due to wrong results/outputs, and consequently you may get zero for that part of the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is importing all necessary python, sklearn and Tensorflow/Keras modules. **You definitely need to add to the imports as you work on the assignment.** When you import a new module, add it here in the same cell. All imports should be in this import cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:15:52.664458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 11:15:52.664488: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "''' Import Cell\n",
    "    Import necessary Python/Sklearn modules as well as Tensorflow/Keras '''\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns # Seaborn, used for graphing\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be no error/output after running this cell if the installation is correct\n",
    "tf.debugging.Assert(tf.__version__ >= '2.0.0', [\"You should install Tensorflow 2.x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-I - Multi-Class Classification Using NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part-I, you're going to use tf/keras to build a NN for multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the dataset `Sensorless_drive_diagnosis.txt` from [UCI ML Repository page](https://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis#). The dataset file is in the `Data Folder`.\n",
    "\n",
    "\"Features are extracted from motor current. The motor has intact and defective components. This results in 11 different classes with different conditions.\" You're going to predict these 11 classes. Therefore, this is a multi-class classification problem.\n",
    "\n",
    "Load the text file using pandas `read_csv` considering that the separator is a space `' '`  and the file has no header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58509, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.03171</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.03081</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.03288</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0 -3.014600e-07  0.000008 -0.000012 -0.000002 -0.000001 -0.000021  0.031718   \n",
       "1  2.913200e-06 -0.000005  0.000003 -0.000006  0.000003 -0.000004  0.030804   \n",
       "2 -2.951700e-06 -0.000003 -0.000016 -0.000001 -0.000002  0.000017  0.032877   \n",
       "\n",
       "        7         8         9   ...       39      40      41      42      43  \\\n",
       "0  0.03171  0.031721 -0.032963  ... -0.63308  2.9646  8.1198 -1.4961 -1.4961   \n",
       "1  0.03081  0.030806 -0.033520  ... -0.59314  7.6252  6.1690 -1.4967 -1.4967   \n",
       "2  0.03288  0.032896 -0.029834  ... -0.63252  2.7784  5.3017 -1.4983 -1.4983   \n",
       "\n",
       "       44      45      46      47  48  \n",
       "0 -1.4961 -1.4996 -1.4996 -1.4996   1  \n",
       "1 -1.4967 -1.5005 -1.5005 -1.5005   1  \n",
       "2 -1.4982 -1.4985 -1.4985 -1.4985   1  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('Sensorless_drive_diagnosis.txt', sep = ' ', header=None)\n",
    "\n",
    "print(data1.shape)\n",
    "data1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the file has no header, column names are integers from 0 to 48, and the last column is the target class. Name the columns from `col1` to `col49` as specified in the provided output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "      <th>col49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           col1          col2      col3      col4          col5      col6  \\\n",
       "0 -3.014600e-07  8.260300e-06 -0.000012 -0.000002 -1.438600e-06 -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06  0.000003 -0.000006  2.778900e-06 -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06 -0.000016 -0.000001 -1.575300e-06  0.000017   \n",
       "3 -1.322600e-06  8.820100e-06 -0.000016 -0.000005 -7.282900e-07  0.000004   \n",
       "4 -6.836600e-08  5.666300e-07 -0.000026 -0.000006 -7.940600e-07  0.000013   \n",
       "\n",
       "       col7      col8      col9     col10  ...    col40   col41   col42  \\\n",
       "0  0.031718  0.031710  0.031721 -0.032963  ... -0.63308  2.9646  8.1198   \n",
       "1  0.030804  0.030810  0.030806 -0.033520  ... -0.59314  7.6252  6.1690   \n",
       "2  0.032877  0.032880  0.032896 -0.029834  ... -0.63252  2.7784  5.3017   \n",
       "3  0.029410  0.029401  0.029417 -0.030156  ... -0.62289  6.5534  6.2606   \n",
       "4  0.030119  0.030119  0.030145 -0.031393  ... -0.63010  4.5155  9.5231   \n",
       "\n",
       "    col43   col44   col45   col46   col47   col48  col49  \n",
       "0 -1.4961 -1.4961 -1.4961 -1.4996 -1.4996 -1.4996      1  \n",
       "1 -1.4967 -1.4967 -1.4967 -1.5005 -1.5005 -1.5005      1  \n",
       "2 -1.4983 -1.4983 -1.4982 -1.4985 -1.4985 -1.4985      1  \n",
       "3 -1.4963 -1.4963 -1.4963 -1.4975 -1.4975 -1.4976      1  \n",
       "4 -1.4958 -1.4958 -1.4958 -1.4959 -1.4959 -1.4959      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "names = []  # Holds new column names \n",
    "\n",
    "while i <= 49:  # Loop 49 times to get 'col' + str(i), add to list \n",
    "    names.append('col' + str(i))\n",
    "    i+= 1\n",
    "\n",
    "data1.set_axis(names, axis=1, inplace=True)  # Set column names to names list\n",
    "\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename the last column, i.e. the target column, from `col49` to `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           col1          col2      col3      col4          col5      col6  \\\n",
       "0 -3.014600e-07  8.260300e-06 -0.000012 -0.000002 -1.438600e-06 -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06  0.000003 -0.000006  2.778900e-06 -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06 -0.000016 -0.000001 -1.575300e-06  0.000017   \n",
       "3 -1.322600e-06  8.820100e-06 -0.000016 -0.000005 -7.282900e-07  0.000004   \n",
       "4 -6.836600e-08  5.666300e-07 -0.000026 -0.000006 -7.940600e-07  0.000013   \n",
       "\n",
       "       col7      col8      col9     col10  ...    col40   col41   col42  \\\n",
       "0  0.031718  0.031710  0.031721 -0.032963  ... -0.63308  2.9646  8.1198   \n",
       "1  0.030804  0.030810  0.030806 -0.033520  ... -0.59314  7.6252  6.1690   \n",
       "2  0.032877  0.032880  0.032896 -0.029834  ... -0.63252  2.7784  5.3017   \n",
       "3  0.029410  0.029401  0.029417 -0.030156  ... -0.62289  6.5534  6.2606   \n",
       "4  0.030119  0.030119  0.030145 -0.031393  ... -0.63010  4.5155  9.5231   \n",
       "\n",
       "    col43   col44   col45   col46   col47   col48  class  \n",
       "0 -1.4961 -1.4961 -1.4961 -1.4996 -1.4996 -1.4996      1  \n",
       "1 -1.4967 -1.4967 -1.4967 -1.5005 -1.5005 -1.5005      1  \n",
       "2 -1.4983 -1.4983 -1.4982 -1.4985 -1.4985 -1.4985      1  \n",
       "3 -1.4963 -1.4963 -1.4963 -1.4975 -1.4975 -1.4976      1  \n",
       "4 -1.4958 -1.4958 -1.4958 -1.4959 -1.4959 -1.4959      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[-1] = 'class'  # Change last column label to 'class'\n",
    "\n",
    "data1.set_axis(names, axis=1, inplace=True)  # Apply changes to columms\n",
    "\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are 11 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The dataset is balanced with respect to 11 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1     5319\n",
       "2     5319\n",
       "3     5319\n",
       "4     5319\n",
       "5     5319\n",
       "6     5319\n",
       "7     5319\n",
       "8     5319\n",
       "9     5319\n",
       "10    5319\n",
       "11    5319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.groupby('class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1     0\n",
       "col2     0\n",
       "col3     0\n",
       "col4     0\n",
       "col5     0\n",
       "col6     0\n",
       "col7     0\n",
       "col8     0\n",
       "col9     0\n",
       "col10    0\n",
       "col11    0\n",
       "col12    0\n",
       "col13    0\n",
       "col14    0\n",
       "col15    0\n",
       "col16    0\n",
       "col17    0\n",
       "col18    0\n",
       "col19    0\n",
       "col20    0\n",
       "col21    0\n",
       "col22    0\n",
       "col23    0\n",
       "col24    0\n",
       "col25    0\n",
       "col26    0\n",
       "col27    0\n",
       "col28    0\n",
       "col29    0\n",
       "col30    0\n",
       "col31    0\n",
       "col32    0\n",
       "col33    0\n",
       "col34    0\n",
       "col35    0\n",
       "col36    0\n",
       "col37    0\n",
       "col38    0\n",
       "col39    0\n",
       "col40    0\n",
       "col41    0\n",
       "col42    0\n",
       "col43    0\n",
       "col44    0\n",
       "col45    0\n",
       "col46    0\n",
       "col47    0\n",
       "col48    0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NAs, and drop NAs if there is any\n",
    "data1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate features from the target column, so `X` should contain all feature columns `col1` to `col48` and of course should NOT include `class`. `y` should contain `class` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58509, 48)\n",
      "(58509,)\n"
     ]
    }
   ],
   "source": [
    "X = data1.drop('class', axis=1)\n",
    "y = data1['class']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col39</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58509.000000</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.439648e-06</td>\n",
       "      <td>1.412013e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>1.351239e-06</td>\n",
       "      <td>-2.654483e-07</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>-0.011897</td>\n",
       "      <td>...</td>\n",
       "      <td>8.406765</td>\n",
       "      <td>-0.397757</td>\n",
       "      <td>7.293781</td>\n",
       "      <td>8.273772</td>\n",
       "      <td>-1.500887</td>\n",
       "      <td>-1.500912</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.497771</td>\n",
       "      <td>-1.497794</td>\n",
       "      <td>-1.497686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>5.555429e-05</td>\n",
       "      <td>2.353009e-04</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>5.660943e-05</td>\n",
       "      <td>2.261907e-04</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.036470</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>...</td>\n",
       "      <td>6.897301</td>\n",
       "      <td>25.018728</td>\n",
       "      <td>12.451781</td>\n",
       "      <td>6.565952</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.013721</td>\n",
       "      <td>-5.414400e-03</td>\n",
       "      <td>-1.358000e-02</td>\n",
       "      <td>-0.012787</td>\n",
       "      <td>-8.355900e-03</td>\n",
       "      <td>-9.741300e-03</td>\n",
       "      <td>-0.139890</td>\n",
       "      <td>-0.135940</td>\n",
       "      <td>-0.130860</td>\n",
       "      <td>-0.218640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>-0.596830</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>-1.525500</td>\n",
       "      <td>-1.526200</td>\n",
       "      <td>-1.523700</td>\n",
       "      <td>-1.521400</td>\n",
       "      <td>-1.523200</td>\n",
       "      <td>-1.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.444400e-05</td>\n",
       "      <td>-7.239600e-05</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-1.475300e-05</td>\n",
       "      <td>-7.379100e-05</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>-0.019951</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>-0.032144</td>\n",
       "      <td>...</td>\n",
       "      <td>4.451300</td>\n",
       "      <td>-0.715470</td>\n",
       "      <td>1.450300</td>\n",
       "      <td>4.436300</td>\n",
       "      <td>-1.503300</td>\n",
       "      <td>-1.503400</td>\n",
       "      <td>-1.503200</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>8.804600e-07</td>\n",
       "      <td>5.137700e-07</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>7.540200e-07</td>\n",
       "      <td>-1.659300e-07</td>\n",
       "      <td>0.013226</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>-0.015566</td>\n",
       "      <td>...</td>\n",
       "      <td>6.566800</td>\n",
       "      <td>-0.661710</td>\n",
       "      <td>3.301300</td>\n",
       "      <td>6.479100</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.877700e-05</td>\n",
       "      <td>7.520000e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.906200e-05</td>\n",
       "      <td>7.138600e-05</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>...</td>\n",
       "      <td>9.952600</td>\n",
       "      <td>-0.573980</td>\n",
       "      <td>8.288500</td>\n",
       "      <td>9.857500</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>-1.496300</td>\n",
       "      <td>-1.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.005784</td>\n",
       "      <td>4.525300e-03</td>\n",
       "      <td>5.237700e-03</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>8.245100e-04</td>\n",
       "      <td>2.753600e-03</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.069130</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.352580</td>\n",
       "      <td>...</td>\n",
       "      <td>265.330000</td>\n",
       "      <td>3670.800000</td>\n",
       "      <td>889.930000</td>\n",
       "      <td>153.150000</td>\n",
       "      <td>-1.457600</td>\n",
       "      <td>-1.456100</td>\n",
       "      <td>-1.455500</td>\n",
       "      <td>-1.337200</td>\n",
       "      <td>-1.337200</td>\n",
       "      <td>-1.337100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               col1          col2          col3          col4          col5  \\\n",
       "count  58509.000000  5.850900e+04  5.850900e+04  58509.000000  5.850900e+04   \n",
       "mean      -0.000003  1.439648e-06  1.412013e-06     -0.000001  1.351239e-06   \n",
       "std        0.000072  5.555429e-05  2.353009e-04      0.000063  5.660943e-05   \n",
       "min       -0.013721 -5.414400e-03 -1.358000e-02     -0.012787 -8.355900e-03   \n",
       "25%       -0.000007 -1.444400e-05 -7.239600e-05     -0.000005 -1.475300e-05   \n",
       "50%       -0.000003  8.804600e-07  5.137700e-07     -0.000001  7.540200e-07   \n",
       "75%        0.000002  1.877700e-05  7.520000e-05      0.000004  1.906200e-05   \n",
       "max        0.005784  4.525300e-03  5.237700e-03      0.001453  8.245100e-04   \n",
       "\n",
       "               col6          col7          col8          col9         col10  \\\n",
       "count  5.850900e+04  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean  -2.654483e-07      0.001915      0.001913      0.001912     -0.011897   \n",
       "std    2.261907e-04      0.036468      0.036465      0.036470      0.066482   \n",
       "min   -9.741300e-03     -0.139890     -0.135940     -0.130860     -0.218640   \n",
       "25%   -7.379100e-05     -0.019927     -0.019951     -0.019925     -0.032144   \n",
       "50%   -1.659300e-07      0.013226      0.013230      0.013247     -0.015566   \n",
       "75%    7.138600e-05      0.024770      0.024776      0.024777      0.020614   \n",
       "max    2.753600e-03      0.069125      0.069130      0.069131      0.352580   \n",
       "\n",
       "       ...         col39         col40         col41         col42  \\\n",
       "count  ...  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean   ...      8.406765     -0.397757      7.293781      8.273772   \n",
       "std    ...      6.897301     25.018728     12.451781      6.565952   \n",
       "min    ...      0.522180     -0.902350     -0.596830      0.320660   \n",
       "25%    ...      4.451300     -0.715470      1.450300      4.436300   \n",
       "50%    ...      6.566800     -0.661710      3.301300      6.479100   \n",
       "75%    ...      9.952600     -0.573980      8.288500      9.857500   \n",
       "max    ...    265.330000   3670.800000    889.930000    153.150000   \n",
       "\n",
       "              col43         col44         col45         col46         col47  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean      -1.500887     -1.500912     -1.500805     -1.497771     -1.497794   \n",
       "std        0.003657      0.003668      0.003632      0.003163      0.003163   \n",
       "min       -1.525500     -1.526200     -1.523700     -1.521400     -1.523200   \n",
       "25%       -1.503300     -1.503400     -1.503200     -1.499600     -1.499600   \n",
       "50%       -1.500300     -1.500300     -1.500300     -1.498100     -1.498100   \n",
       "75%       -1.498200     -1.498200     -1.498200     -1.496200     -1.496300   \n",
       "max       -1.457600     -1.456100     -1.455500     -1.337200     -1.337200   \n",
       "\n",
       "              col48  \n",
       "count  58509.000000  \n",
       "mean      -1.497686  \n",
       "std        0.003175  \n",
       "min       -1.521300  \n",
       "25%       -1.499500  \n",
       "50%       -1.498000  \n",
       "75%       -1.496200  \n",
       "max       -1.337100  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical description of the features\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Statistical description of the features reveals that they have different scales, so you need to normalize `X`.\n",
    "\n",
    "> Use [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) to normalize X to the range (0,1) which is the default range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col39</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703460</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.721049</td>\n",
       "      <td>0.897795</td>\n",
       "      <td>0.910031</td>\n",
       "      <td>0.777923</td>\n",
       "      <td>0.821032</td>\n",
       "      <td>0.817526</td>\n",
       "      <td>0.812942</td>\n",
       "      <td>0.325053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020749</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.429387</td>\n",
       "      <td>0.404692</td>\n",
       "      <td>0.118350</td>\n",
       "      <td>0.126882</td>\n",
       "      <td>0.117807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703624</td>\n",
       "      <td>0.544197</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.897532</td>\n",
       "      <td>0.910491</td>\n",
       "      <td>0.779322</td>\n",
       "      <td>0.816659</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.808366</td>\n",
       "      <td>0.324078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.424153</td>\n",
       "      <td>0.420827</td>\n",
       "      <td>0.395894</td>\n",
       "      <td>0.113464</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.112921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.703324</td>\n",
       "      <td>0.544404</td>\n",
       "      <td>0.720815</td>\n",
       "      <td>0.897872</td>\n",
       "      <td>0.910017</td>\n",
       "      <td>0.781014</td>\n",
       "      <td>0.826577</td>\n",
       "      <td>0.823231</td>\n",
       "      <td>0.818817</td>\n",
       "      <td>0.330531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019933</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>0.400589</td>\n",
       "      <td>0.398003</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.124321</td>\n",
       "      <td>0.132796</td>\n",
       "      <td>0.123779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703407</td>\n",
       "      <td>0.545612</td>\n",
       "      <td>0.720817</td>\n",
       "      <td>0.897619</td>\n",
       "      <td>0.910109</td>\n",
       "      <td>0.779954</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.806266</td>\n",
       "      <td>0.801421</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086379</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.430044</td>\n",
       "      <td>0.426534</td>\n",
       "      <td>0.401760</td>\n",
       "      <td>0.129750</td>\n",
       "      <td>0.138172</td>\n",
       "      <td>0.128664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703472</td>\n",
       "      <td>0.544782</td>\n",
       "      <td>0.720284</td>\n",
       "      <td>0.897501</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.813382</td>\n",
       "      <td>0.809767</td>\n",
       "      <td>0.805061</td>\n",
       "      <td>0.327802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.060214</td>\n",
       "      <td>0.437408</td>\n",
       "      <td>0.433666</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.138436</td>\n",
       "      <td>0.146774</td>\n",
       "      <td>0.137894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col1      col2      col3      col4      col5      col6      col7  \\\n",
       "0  0.703460  0.545556  0.721049  0.897795  0.910031  0.777923  0.821032   \n",
       "1  0.703624  0.544197  0.721839  0.897532  0.910491  0.779322  0.816659   \n",
       "2  0.703324  0.544404  0.720815  0.897872  0.910017  0.781014  0.826577   \n",
       "3  0.703407  0.545612  0.720817  0.897619  0.910109  0.779954  0.809990   \n",
       "4  0.703472  0.544782  0.720284  0.897501  0.910102  0.780702  0.813382   \n",
       "\n",
       "       col8      col9     col10  ...     col39     col40     col41     col42  \\\n",
       "0  0.817526  0.812942  0.325053  ...  0.020749  0.000073  0.003999  0.051032   \n",
       "1  0.813137  0.808366  0.324078  ...  0.011641  0.000084  0.009233  0.038267   \n",
       "2  0.823231  0.818817  0.330531  ...  0.019933  0.000073  0.003790  0.032592   \n",
       "3  0.806266  0.801421  0.329967  ...  0.086379  0.000076  0.008029  0.038866   \n",
       "4  0.809767  0.805061  0.327802  ...  0.017129  0.000074  0.005741  0.060214   \n",
       "\n",
       "      col43     col44     col45     col46     col47     col48  \n",
       "0  0.432990  0.429387  0.404692  0.118350  0.126882  0.117807  \n",
       "1  0.424153  0.420827  0.395894  0.113464  0.122043  0.112921  \n",
       "2  0.400589  0.398003  0.373900  0.124321  0.132796  0.123779  \n",
       "3  0.430044  0.426534  0.401760  0.129750  0.138172  0.128664  \n",
       "4  0.437408  0.433666  0.409091  0.138436  0.146774  0.137894  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use MinMaxScaler() to normalize X features within the range (0,1) with 0 as minimum and 1 as maximum\n",
    "scaler = MinMaxScaler(copy=False)  # Ensures that the changes are 'inplace' - no copying needed\n",
    "scaler.fit(X)  # Fit the scaler to the data\n",
    "scaler.transform(X)  # Transform (normalize) the data\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now the normalized `X` statistics look a lot better! No need to rename the columns to `col1` to `col48` again, we only did it for more clarity before splitting `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col39</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.703304</td>\n",
       "      <td>0.544870</td>\n",
       "      <td>0.721736</td>\n",
       "      <td>0.897865</td>\n",
       "      <td>0.910335</td>\n",
       "      <td>0.779601</td>\n",
       "      <td>0.678442</td>\n",
       "      <td>0.672225</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.361932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.052039</td>\n",
       "      <td>0.362484</td>\n",
       "      <td>0.360748</td>\n",
       "      <td>0.335711</td>\n",
       "      <td>0.128277</td>\n",
       "      <td>0.136594</td>\n",
       "      <td>0.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.174474</td>\n",
       "      <td>0.177820</td>\n",
       "      <td>0.182357</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.013982</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.053250</td>\n",
       "      <td>0.017171</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.017235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.703094</td>\n",
       "      <td>0.543272</td>\n",
       "      <td>0.717814</td>\n",
       "      <td>0.897577</td>\n",
       "      <td>0.908581</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.573944</td>\n",
       "      <td>0.565607</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.326487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014838</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.026930</td>\n",
       "      <td>0.326951</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.300587</td>\n",
       "      <td>0.118350</td>\n",
       "      <td>0.126882</td>\n",
       "      <td>0.118350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.703339</td>\n",
       "      <td>0.544813</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.910270</td>\n",
       "      <td>0.779609</td>\n",
       "      <td>0.732560</td>\n",
       "      <td>0.727410</td>\n",
       "      <td>0.720567</td>\n",
       "      <td>0.355509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022826</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.369472</td>\n",
       "      <td>0.343109</td>\n",
       "      <td>0.126493</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>0.126493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.703556</td>\n",
       "      <td>0.546614</td>\n",
       "      <td>0.725657</td>\n",
       "      <td>0.898207</td>\n",
       "      <td>0.912264</td>\n",
       "      <td>0.785335</td>\n",
       "      <td>0.787790</td>\n",
       "      <td>0.783713</td>\n",
       "      <td>0.778220</td>\n",
       "      <td>0.418847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035612</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.062402</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.399429</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.136808</td>\n",
       "      <td>0.144624</td>\n",
       "      <td>0.136265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               col1          col2          col3          col4          col5  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean       0.703304      0.544870      0.721736      0.897865      0.910335   \n",
       "std        0.003677      0.005589      0.012504      0.004396      0.006166   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.703094      0.543272      0.717814      0.897577      0.908581   \n",
       "50%        0.703339      0.544813      0.721688      0.897883      0.910270   \n",
       "75%        0.703556      0.546614      0.725657      0.898207      0.912264   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               col6          col7          col8          col9         col10  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean       0.779601      0.678442      0.672225      0.663889      0.361932   \n",
       "std        0.018103      0.174474      0.177820      0.182357      0.116387   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.773716      0.573944      0.565607      0.554700      0.326487   \n",
       "50%        0.779609      0.732560      0.727410      0.720567      0.355509   \n",
       "75%        0.785335      0.787790      0.783713      0.778220      0.418847   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         col39         col40         col41         col42  \\\n",
       "count  ...  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean   ...      0.029775      0.000137      0.008861      0.052039   \n",
       "std    ...      0.026046      0.006814      0.013982      0.042963   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.014838      0.000051      0.002299      0.026930   \n",
       "50%    ...      0.022826      0.000066      0.004377      0.040296   \n",
       "75%    ...      0.035612      0.000089      0.009978      0.062402   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              col43         col44         col45         col46         col47  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean       0.362484      0.360748      0.335711      0.128277      0.136594   \n",
       "std        0.053864      0.052318      0.053250      0.017171      0.017007   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.326951      0.325250      0.300587      0.118350      0.126882   \n",
       "50%        0.371134      0.369472      0.343109      0.126493      0.134946   \n",
       "75%        0.402062      0.399429      0.373900      0.136808      0.144624   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              col48  \n",
       "count  58509.000000  \n",
       "mean       0.128200  \n",
       "std        0.017235  \n",
       "min        0.000000  \n",
       "25%        0.118350  \n",
       "50%        0.126493  \n",
       "75%        0.136265  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using pandas [`get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) method, convert `y` to one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(data1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58509, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58504</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58505</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58506</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58509 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2   3   4   5   6   7   8   9   10  11\n",
       "0       1   0   0   0   0   0   0   0   0   0   0\n",
       "1       1   0   0   0   0   0   0   0   0   0   0\n",
       "2       1   0   0   0   0   0   0   0   0   0   0\n",
       "3       1   0   0   0   0   0   0   0   0   0   0\n",
       "4       1   0   0   0   0   0   0   0   0   0   0\n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "58504   0   0   0   0   0   0   0   0   0   0   1\n",
       "58505   0   0   0   0   0   0   0   0   0   0   1\n",
       "58506   0   0   0   0   0   0   0   0   0   0   1\n",
       "58507   0   0   0   0   0   0   0   0   0   0   1\n",
       "58508   0   0   0   0   0   0   0   0   0   0   1\n",
       "\n",
       "[58509 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You need to convert `X` and `y` to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = X.values\n",
    "y = y.values\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46807, 48)\n",
      "(46807, 11)\n",
      "(11702, 48)\n",
      "(11702, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split X, y to train and test with ratio of 80/20 for train/test respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Baseline NN Model for Multi-Class Classification with 85% Validation Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can begin with a simple neural network `baseline_model` with one or two hidden layers, 5-10 neurons per hidden layer, and increase the number of neurons and hidden layers only if needed. You may also use callback and early stopping to find the optimal number of epochs, but it's possible to obtain **the minimum required `val_accuracy` for the baseline model (0.85)** with 20 epochs and a couple of hidden layers only.\n",
    "\n",
    "> <font color='red'>**val_accuracy Requirement**</font>: The minimum required `val_accuracy` of the `baseline_model` after the last epoch of training is 0.85.\n",
    "\n",
    "> **Hints**:\n",
    "\n",
    "> - Since you're not working with image data in this assignment, you should NOT use `Flatten` layers in any of the NNs of this assignment.\n",
    "\n",
    "> - `input_dim` of the first layer should match with the number of features in `X`.\n",
    "\n",
    "> - You may use ReLU for all hidden layers, but you may also try other activation functions for the hidden layers.\n",
    "\n",
    "> - **The most common mistake** is setting wrong activation function and number of neurons in the output layer; recall that the output layer specifications are determined by the type of ML task i.e. Multi-class Classification.\n",
    "\n",
    "> - The loss function in `compile` should match with the one-hot encoded labels in `y` (check tf-notebook instructions and the links to tf documentations).\n",
    "\n",
    "> - During training, you should see a clear trend of decreasing loss and increasing accuracy in the first few epochs; otherwise, that is a red flag that your model has not been developed properly, thus, stop training, fix the issues and then train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Very Important Note**: Training NNs and DNNs take a lot of time and efforts, and you need to do lots of experiments. While the hints and the provided outputs can be helpful, you are responsible to explore, investigate, and try as many necessary steps and approaches as needed and use the discussions and contents of the lectures/textbook/slides to achieve the desired results and to get credit for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:16:05.149220: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-26 11:16:05.149244: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-26 11:16:05.149264: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jacob): /proc/driver/nvidia/version does not exist\n",
      "2022-04-26 11:16:05.150384: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "''' build the baseline_model\n",
    "    be careful about the input_dim and the output layer specifications\n",
    "    start with a simple model and change the model hyperparameters as needed '''\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=None)\n",
    "baseline_hidden1 = keras.layers.Dense(24, input_shape=(48,), activation='relu')  # Input layer; same dims as features in X\n",
    "baseline_hidden2 = keras.layers.Dense(24, activation='relu', kernel_initializer=initializer)\n",
    "baseline_output = keras.layers.Dense(11, activation='softmax')\n",
    "\n",
    "baseline_model = keras.Sequential([\n",
    "    baseline_hidden1,\n",
    "    baseline_hidden2,\n",
    "    baseline_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                1176      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                275       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,051\n",
      "Trainable params: 2,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' get the baseline_model summary '''\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' compile the baseline_model\n",
    "    be careful with the loss function, it should work with one-hot encoded labels\n",
    "    metric should be accuracy\n",
    "    you can choose your optimizer and learning_rate '''\n",
    "opt = keras.optimizers.Adam(learning_rate=0.004)\n",
    "\n",
    "baseline_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 1.0408 - accuracy: 0.5919 - val_loss: 0.5591 - val_accuracy: 0.7783\n",
      "Epoch 2/20\n",
      "1317/1317 [==============================] - 5s 4ms/step - loss: 0.4885 - accuracy: 0.7977 - val_loss: 0.4144 - val_accuracy: 0.8272\n",
      "Epoch 3/20\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.4076 - accuracy: 0.8266 - val_loss: 0.4060 - val_accuracy: 0.8250\n",
      "Epoch 4/20\n",
      "1317/1317 [==============================] - 5s 4ms/step - loss: 0.3792 - accuracy: 0.8350 - val_loss: 0.3468 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "1317/1317 [==============================] - 5s 4ms/step - loss: 0.3619 - accuracy: 0.8421 - val_loss: 0.3504 - val_accuracy: 0.8549\n",
      "Epoch 6/20\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.3471 - accuracy: 0.8497 - val_loss: 0.3201 - val_accuracy: 0.8716\n",
      "Epoch 7/20\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.3327 - accuracy: 0.8592 - val_loss: 0.3106 - val_accuracy: 0.8761\n",
      "Epoch 8/20\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.3175 - accuracy: 0.8670 - val_loss: 0.2888 - val_accuracy: 0.8876\n",
      "Epoch 9/20\n",
      "1317/1317 [==============================] - 7s 5ms/step - loss: 0.3032 - accuracy: 0.8744 - val_loss: 0.2852 - val_accuracy: 0.8898\n",
      "Epoch 10/20\n",
      "1317/1317 [==============================] - 7s 5ms/step - loss: 0.2958 - accuracy: 0.8781 - val_loss: 0.2658 - val_accuracy: 0.8970\n",
      "Epoch 11/20\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.2793 - accuracy: 0.8871 - val_loss: 0.3122 - val_accuracy: 0.8823\n",
      "Epoch 12/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2684 - accuracy: 0.8919 - val_loss: 0.2731 - val_accuracy: 0.8915\n",
      "Epoch 13/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2636 - accuracy: 0.8944 - val_loss: 0.2546 - val_accuracy: 0.9007\n",
      "Epoch 14/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2548 - accuracy: 0.9008 - val_loss: 0.2529 - val_accuracy: 0.9060\n",
      "Epoch 15/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2503 - accuracy: 0.9006 - val_loss: 0.2654 - val_accuracy: 0.8945\n",
      "Epoch 16/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2444 - accuracy: 0.9039 - val_loss: 0.3147 - val_accuracy: 0.8757\n",
      "Epoch 17/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2407 - accuracy: 0.9066 - val_loss: 0.2135 - val_accuracy: 0.9244\n",
      "Epoch 18/20\n",
      "1317/1317 [==============================] - 2s 2ms/step - loss: 0.2365 - accuracy: 0.9085 - val_loss: 0.2074 - val_accuracy: 0.9235\n",
      "Epoch 19/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2333 - accuracy: 0.9103 - val_loss: 0.2840 - val_accuracy: 0.8859\n",
      "Epoch 20/20\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2282 - accuracy: 0.9116 - val_loss: 0.2100 - val_accuracy: 0.9225\n"
     ]
    }
   ],
   "source": [
    "''' train the baseline_model on X_train, y_train with 20 epochs and a validation_split=0.1\n",
    "    You may increase number of epochs or use callbacks and early stopping if needed\n",
    "    The minimum required val_accuracy after the last epoch is 0.85 '''\n",
    "\n",
    "baseline_model_history = baseline_model.fit(X_train, y_train, epochs=20, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot the history with figsize=(10,5)\n",
    "    the plot should display the grid and the whole range of values for loss and accuracy '''\n",
    "\n",
    "pd.DataFrame(baseline_model_history.history).plot(figsize=(10,5))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: After each training session, the model contains some trained weights, so if you want to make changes to your NN and re-run your experiments with a new random initilization of weights, you should re-run the build-model cell to clear and re-initialize the weights randomly, and then compile it again so that you can have a fresh restart of your updated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building `nn_clf` with 99% Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a working `baseline_model` with 85% `val_accuracy`, you should build a NN classifier `nn_clf` that can achieve a **test accuracy** of 99%. You can start with the same architecture of your `baseline_model` and increase the compleixty of `nn_clf` gradually if needed. Recall that some train/test splits are easier for the model to learn from, so if your accuracy is getting so close but not hitting 0.99, you may want to re-split train/test in addition to the changes you may want to make on your model.\n",
    "\n",
    "> **Note**: Any hint given in this notebook is just a suggestion and may or may not work with your model depending on the configurations of your model, so you should try as many different configurations, techniques, and approaches as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build nn_clf\n",
    "nn_clf_hidden1 = keras.layers.Dense(48, input_shape=(48,), activation='relu', kernel_initializer=initializer)  # Gets input from input layer\n",
    "nn_clf_hidden2 = keras.layers.Dense(48, activation='relu', kernel_initializer=initializer)  # 48 Dense Neurons using RELU\n",
    "nn_clf_hidden3 = keras.layers.Dense(48, activation='relu', kernel_initializer=initializer)  # 48 Dense Neurons using RELU\n",
    "nn_clf_output = keras.layers.Dense(11, activation='softmax') # Output layer uses Softmax for multiclass (11 classes)\n",
    "\n",
    "nn_clf  = keras.Sequential([\n",
    "    nn_clf_hidden1,\n",
    "    nn_clf_hidden2,\n",
    "    nn_clf_hidden3,\n",
    "    nn_clf_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell used to create a callback class that stops when accuracy reaches 99% or higher\n",
    "class nn_clf_callback(tf.keras.callbacks.Callback):  # Custom callback that stops training when val_accuracy > 0.99\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy') > 0.99):\n",
    "            print(\"\\nReached 99% accuracy, training stopped early.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = nn_clf_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Compile nn_clf - metric is 'accuracy' and be careful to choose the loss properly\n",
    "    Hint1: One of the hyperparameters you can change is the optimizer (Adam, RMSprop, SGD, ...)\n",
    "    Hint2: The other impactful hyperparameter is learning_rate '''\n",
    "nn_clf_opt = tf.keras.optimizers.Adam(learning_rate=0.004)\n",
    "\n",
    "nn_clf.compile(\n",
    "    optimizer=nn_clf_opt,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1317/1317 [==============================] - 8s 6ms/step - loss: 0.7957 - accuracy: 0.6532 - val_loss: 0.4190 - val_accuracy: 0.8086\n",
      "Epoch 2/200\n",
      "1317/1317 [==============================] - 8s 6ms/step - loss: 0.4194 - accuracy: 0.8189 - val_loss: 0.3232 - val_accuracy: 0.8703\n",
      "Epoch 3/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.3669 - accuracy: 0.8441 - val_loss: 0.4790 - val_accuracy: 0.7958\n",
      "Epoch 4/200\n",
      "1317/1317 [==============================] - 7s 5ms/step - loss: 0.3118 - accuracy: 0.8725 - val_loss: 0.3901 - val_accuracy: 0.8445\n",
      "Epoch 5/200\n",
      "1317/1317 [==============================] - 8s 6ms/step - loss: 0.2804 - accuracy: 0.8905 - val_loss: 0.2374 - val_accuracy: 0.9013\n",
      "Epoch 6/200\n",
      "1317/1317 [==============================] - 7s 6ms/step - loss: 0.2361 - accuracy: 0.9073 - val_loss: 0.1735 - val_accuracy: 0.9361\n",
      "Epoch 7/200\n",
      "1317/1317 [==============================] - 7s 5ms/step - loss: 0.2444 - accuracy: 0.9071 - val_loss: 0.1636 - val_accuracy: 0.9413\n",
      "Epoch 8/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.2031 - accuracy: 0.9198 - val_loss: 0.1895 - val_accuracy: 0.9284\n",
      "Epoch 9/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.1983 - accuracy: 0.9217 - val_loss: 0.1789 - val_accuracy: 0.9344\n",
      "Epoch 10/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.1894 - accuracy: 0.9261 - val_loss: 0.1369 - val_accuracy: 0.9517\n",
      "Epoch 11/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.1766 - accuracy: 0.9314 - val_loss: 0.1700 - val_accuracy: 0.9340\n",
      "Epoch 12/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1678 - accuracy: 0.9374 - val_loss: 0.1149 - val_accuracy: 0.9605\n",
      "Epoch 13/200\n",
      "1317/1317 [==============================] - 7s 5ms/step - loss: 0.1524 - accuracy: 0.9413 - val_loss: 0.1536 - val_accuracy: 0.9427\n",
      "Epoch 14/200\n",
      "1317/1317 [==============================] - 7s 5ms/step - loss: 0.1554 - accuracy: 0.9418 - val_loss: 0.1041 - val_accuracy: 0.9613\n",
      "Epoch 15/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1386 - accuracy: 0.9473 - val_loss: 0.1012 - val_accuracy: 0.9665\n",
      "Epoch 16/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1331 - accuracy: 0.9488 - val_loss: 0.1184 - val_accuracy: 0.9554\n",
      "Epoch 17/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.1348 - accuracy: 0.9496 - val_loss: 0.0968 - val_accuracy: 0.9639\n",
      "Epoch 18/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1231 - accuracy: 0.9535 - val_loss: 0.0877 - val_accuracy: 0.9669\n",
      "Epoch 19/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1202 - accuracy: 0.9558 - val_loss: 0.0807 - val_accuracy: 0.9718\n",
      "Epoch 20/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1173 - accuracy: 0.9560 - val_loss: 0.1187 - val_accuracy: 0.9500\n",
      "Epoch 21/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1088 - accuracy: 0.9596 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
      "Epoch 22/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.1033 - accuracy: 0.9619 - val_loss: 0.1719 - val_accuracy: 0.9438\n",
      "Epoch 23/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.0934 - accuracy: 0.9648 - val_loss: 0.1902 - val_accuracy: 0.9340\n",
      "Epoch 24/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.1017 - accuracy: 0.9609 - val_loss: 0.1271 - val_accuracy: 0.9524\n",
      "Epoch 25/200\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0993 - accuracy: 0.9639 - val_loss: 0.0701 - val_accuracy: 0.9763\n",
      "Epoch 26/200\n",
      "1317/1317 [==============================] - 4s 3ms/step - loss: 0.0954 - accuracy: 0.9646 - val_loss: 0.0832 - val_accuracy: 0.9697\n",
      "Epoch 27/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0966 - accuracy: 0.9645 - val_loss: 0.1539 - val_accuracy: 0.9417\n",
      "Epoch 28/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0945 - accuracy: 0.9656 - val_loss: 0.0704 - val_accuracy: 0.9718\n",
      "Epoch 29/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0871 - accuracy: 0.9677 - val_loss: 0.0557 - val_accuracy: 0.9797\n",
      "Epoch 30/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0828 - accuracy: 0.9682 - val_loss: 0.3439 - val_accuracy: 0.8893\n",
      "Epoch 31/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1006 - accuracy: 0.9649 - val_loss: 0.0949 - val_accuracy: 0.9596\n",
      "Epoch 32/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0778 - accuracy: 0.9711 - val_loss: 0.0625 - val_accuracy: 0.9776\n",
      "Epoch 33/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0730 - accuracy: 0.9727 - val_loss: 0.0509 - val_accuracy: 0.9831\n",
      "Epoch 34/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0858 - accuracy: 0.9692 - val_loss: 0.1126 - val_accuracy: 0.9549\n",
      "Epoch 35/200\n",
      "1317/1317 [==============================] - 4s 3ms/step - loss: 0.0788 - accuracy: 0.9713 - val_loss: 0.0828 - val_accuracy: 0.9684\n",
      "Epoch 36/200\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 0.0817 - accuracy: 0.9692 - val_loss: 0.1804 - val_accuracy: 0.9361\n",
      "Epoch 37/200\n",
      "1317/1317 [==============================] - 4s 3ms/step - loss: 0.0659 - accuracy: 0.9753 - val_loss: 0.0364 - val_accuracy: 0.9863\n",
      "Epoch 38/200\n",
      "1317/1317 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.9697 - val_loss: 0.0349 - val_accuracy: 0.9876\n",
      "Epoch 39/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0860 - accuracy: 0.9690 - val_loss: 0.0701 - val_accuracy: 0.9729\n",
      "Epoch 40/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0713 - accuracy: 0.9740 - val_loss: 0.0428 - val_accuracy: 0.9844\n",
      "Epoch 41/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0683 - accuracy: 0.9741 - val_loss: 0.0313 - val_accuracy: 0.9878\n",
      "Epoch 42/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0715 - accuracy: 0.9736 - val_loss: 0.0402 - val_accuracy: 0.9853\n",
      "Epoch 43/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 0.0906 - val_accuracy: 0.9688\n",
      "Epoch 44/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0610 - accuracy: 0.9784 - val_loss: 0.0377 - val_accuracy: 0.9865\n",
      "Epoch 45/200\n",
      "1317/1317 [==============================] - 4s 3ms/step - loss: 0.0675 - accuracy: 0.9750 - val_loss: 0.0904 - val_accuracy: 0.9652\n",
      "Epoch 46/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0708 - accuracy: 0.9739 - val_loss: 0.0495 - val_accuracy: 0.9791\n",
      "Epoch 47/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0655 - accuracy: 0.9761 - val_loss: 0.0601 - val_accuracy: 0.9748\n",
      "Epoch 48/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0689 - accuracy: 0.9748 - val_loss: 0.0376 - val_accuracy: 0.9853\n",
      "Epoch 49/200\n",
      "1317/1317 [==============================] - 4s 3ms/step - loss: 0.0663 - accuracy: 0.9758 - val_loss: 0.0680 - val_accuracy: 0.9733\n",
      "Epoch 50/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0727 - accuracy: 0.9735 - val_loss: 0.1222 - val_accuracy: 0.9571\n",
      "Epoch 51/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0653 - accuracy: 0.9767 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
      "Epoch 52/200\n",
      "1317/1317 [==============================] - 3s 3ms/step - loss: 0.0596 - accuracy: 0.9784 - val_loss: 0.0535 - val_accuracy: 0.9789\n",
      "Epoch 53/200\n",
      "1317/1317 [==============================] - 3s 3ms/step - loss: 0.0623 - accuracy: 0.9778 - val_loss: 0.0382 - val_accuracy: 0.9844\n",
      "Epoch 54/200\n",
      "1317/1317 [==============================] - 3s 3ms/step - loss: 0.0645 - accuracy: 0.9767 - val_loss: 0.0622 - val_accuracy: 0.9744\n",
      "Epoch 55/200\n",
      "1317/1317 [==============================] - 3s 3ms/step - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.1558 - val_accuracy: 0.9521\n",
      "Epoch 56/200\n",
      "1317/1317 [==============================] - 3s 3ms/step - loss: 0.0671 - accuracy: 0.9766 - val_loss: 0.0568 - val_accuracy: 0.9797\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.0830 - val_accuracy: 0.9695\n",
      "Epoch 58/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0569 - accuracy: 0.9792 - val_loss: 0.0440 - val_accuracy: 0.9818\n",
      "Epoch 59/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0650 - accuracy: 0.9768 - val_loss: 0.0578 - val_accuracy: 0.9810\n",
      "Epoch 60/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.0333 - val_accuracy: 0.9889\n",
      "Epoch 61/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0639 - accuracy: 0.9770 - val_loss: 0.0812 - val_accuracy: 0.9718\n",
      "Epoch 62/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0670 - accuracy: 0.9762 - val_loss: 0.0589 - val_accuracy: 0.9784\n",
      "Epoch 63/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0598 - accuracy: 0.9787 - val_loss: 0.0389 - val_accuracy: 0.9872\n",
      "Epoch 64/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0648 - accuracy: 0.9770 - val_loss: 0.0801 - val_accuracy: 0.9712\n",
      "Epoch 65/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.0517 - val_accuracy: 0.9806\n",
      "Epoch 66/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0506 - accuracy: 0.9819 - val_loss: 0.0703 - val_accuracy: 0.9765\n",
      "Epoch 67/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0640 - val_accuracy: 0.9774\n",
      "Epoch 68/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0419 - val_accuracy: 0.9840\n",
      "Epoch 69/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0566 - accuracy: 0.9806 - val_loss: 0.2079 - val_accuracy: 0.9468\n",
      "Epoch 70/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0538 - accuracy: 0.9806 - val_loss: 0.0521 - val_accuracy: 0.9808\n",
      "Epoch 71/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0573 - accuracy: 0.9800 - val_loss: 0.0483 - val_accuracy: 0.9870\n",
      "Epoch 72/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0513 - accuracy: 0.9811 - val_loss: 0.1537 - val_accuracy: 0.9494\n",
      "Epoch 73/200\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0577 - accuracy: 0.9793 - val_loss: 0.0393 - val_accuracy: 0.9848\n",
      "Epoch 74/200\n",
      "1300/1317 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9802\n",
      "Reached 99% accuracy, training stopped early.\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.0583 - accuracy: 0.9803 - val_loss: 0.0215 - val_accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "''' train nn_clf on X_train, y_train with validation_split=0.1\n",
    "     Hint: You may use EarlyStopping and set the patience parameter,\n",
    "     but then you should check in the following cell whether the \"test\" accuracy reaches to 0.99,\n",
    "     and make changes to compile and nn_clf hyperparameters if needed '''\n",
    "\n",
    "nn_clf_history = nn_clf.fit(X_train, y_train, epochs=200, validation_split = 0.1, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot the history with a figsize of (10,5)\n",
    "    the plot should display the grid and the whole range of values for loss and accuracy '''\n",
    "# nn_clf.save(\"99pct_acc_thank_the_machine_gods.h5\")  # Save the model because good lord did this take a while :(\n",
    "# Saved model that procudes 0.9908 test accuracy, no need to save anymore\n",
    "\n",
    "pd.DataFrame(nn_clf_history.history).plot(figsize=(10,5))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To evaluate the model, you should use `evaluate()` method on the test set `X_test`.\n",
    "\n",
    "> <font color='red'>**Test Accuracy Requirement**</font>: Your accuracy on `X_test` should be **0.99** (rounded with two decimal places). Otherwise, your `nn_clf` will get no points for this part, so you should fine-tune the hyperparametrs of your `nn_clf` (number of neurons, hidden layers, etc.) and `compile` (such as optimizer, learning rate, etc.) accordingly.\n",
    "\n",
    "> **Hint**: Keep in mind that the best model is not always the most complex model, it should best fit with your data. You should start with a simple model as you did with the `baseline_model`, and increase the model complexity (number of neurons and hidden layers) gradually and when/if needed.\n",
    "\n",
    "> Recall that each time you want to run a new training session by calling `.fit()` method, you should re-run the build `nn_clf` and `compile` cells to re-start with a fresh random initilization of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366/366 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9920\n",
      "Test accuracy: 0.9919672012329102%\n",
      "Test accuracy is >= 99%, test passed!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate nn_clf on X_test, y_test\n",
    "# Required Test Accuracy: 0.99\n",
    "\n",
    "# A good model that produces the required results was saved just in case something goes wrong with testing\n",
    "# by a grader or something similar. Uncomment to use saved model on the test instead of most current model.\n",
    "\n",
    "# nn_clf = keras.models.load_model('99pct_acc_thank_the_machine_gods.h5')\n",
    "nn_clf_loss, nn_clf_test_accuracy = nn_clf.evaluate(X_test, y_test)  # :)\n",
    "print('Test accuracy: ' + str(nn_clf_test_accuracy) + '%')\n",
    "\n",
    "if nn_clf_test_accuracy >= 0.99:\n",
    "    print(\"Test accuracy is >= 99%, test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the Impact of Learning Rate on Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you're going to plot the impact of learning-rate on accuracy specifically. To do so and to avoid repeating the code, you should write a function `build_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        keras.layers.Dense(48, input_shape=(48,), activation='relu', kernel_initializer=initializer),\n",
    "        keras.layers.Dense(48, activation='relu', kernel_initializer=initializer),\n",
    "        keras.layers.Dense(48, activation='relu', kernel_initializer=initializer),\n",
    "        keras.layers.Dense(11, activation='softmax') # Output layer uses Softmax for multiclass\n",
    "        ])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The **learning rate range** that you're going to investigate is between [0.001, 0.01] inclusive with an increment step of 0.001. Use the optimizer and other hyperparatmeters of your choice that performed the best in your fine-tuning of `nn_clf` in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates range - the for loop of the following experiment will iterate over this array\n",
    "learning_rates = np.arange(0.001, 0.011, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(learning_rates))\n",
    "learning_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: For the following experiment, you should compile the model with `accuracy` as the metric, and use the same loss function that was used for `baseline_model` and `nn_clf` in each iteration of the `for` loop.\n",
    "\n",
    "> Running this cell may take a a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 0.001\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 1.0671 - accuracy: 0.5674\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.5046 - accuracy: 0.7939\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.4100 - accuracy: 0.8260\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3853 - accuracy: 0.8361\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 5s 3ms/step - loss: 0.3663 - accuracy: 0.8421\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.3499 - accuracy: 0.8489\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8603\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8738\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2705 - accuracy: 0.8897\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2595 - accuracy: 0.8953\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.2360 - accuracy: 0.9069\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2204 - accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2029 - accuracy: 0.9193\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1972 - accuracy: 0.9233\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1855 - accuracy: 0.9274\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9336\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1712 - accuracy: 0.9352\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1525 - accuracy: 0.9434\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1521 - accuracy: 0.9429\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1404 - accuracy: 0.9479\n",
      "366/366 [==============================] - 1s 1ms/step - loss: 0.1711 - accuracy: 0.9501\n",
      "Test Accuracy for Learning Rate 0.001: 0.9500939846038818\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.002\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.7951 - accuracy: 0.6726\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.4181 - accuracy: 0.8209\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.3552 - accuracy: 0.8480\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8666\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2873 - accuracy: 0.8838\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2485 - accuracy: 0.9016\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2259 - accuracy: 0.9114\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2091 - accuracy: 0.9171\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1940 - accuracy: 0.9217\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1797 - accuracy: 0.9293\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9344\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1613 - accuracy: 0.9385\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 5s 3ms/step - loss: 0.1466 - accuracy: 0.9434\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 5s 3ms/step - loss: 0.1370 - accuracy: 0.9487\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9466\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 4s 2ms/step - loss: 0.1250 - accuracy: 0.9537\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1272 - accuracy: 0.9520\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1121 - accuracy: 0.9586\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1118 - accuracy: 0.9589\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1044 - accuracy: 0.9615\n",
      "366/366 [==============================] - 1s 1ms/step - loss: 0.1617 - accuracy: 0.9437\n",
      "Test Accuracy for Learning Rate 0.002: 0.9436848163604736\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.003\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.8694 - accuracy: 0.6220\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.4201 - accuracy: 0.8199\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3445 - accuracy: 0.8539\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3058 - accuracy: 0.8740\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.2607 - accuracy: 0.8950\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2404 - accuracy: 0.9045\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2299 - accuracy: 0.9069\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2056 - accuracy: 0.9195\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1924 - accuracy: 0.9241\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1807 - accuracy: 0.9302\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1723 - accuracy: 0.9338\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1683 - accuracy: 0.9363\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1528 - accuracy: 0.9411\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1299 - accuracy: 0.9509\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1348 - accuracy: 0.9499\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1156 - accuracy: 0.9574\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.1171 - accuracy: 0.9571\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.1065 - accuracy: 0.9602\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 4s 2ms/step - loss: 0.1084 - accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.0957 - accuracy: 0.9653\n",
      "366/366 [==============================] - 2s 4ms/step - loss: 0.1328 - accuracy: 0.9580\n",
      "Test Accuracy for Learning Rate 0.003: 0.9580413699150085\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.004\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.7505 - accuracy: 0.6843\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.4126 - accuracy: 0.8195\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3661 - accuracy: 0.8415\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.3141 - accuracy: 0.8694\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.2824 - accuracy: 0.8851\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.2575 - accuracy: 0.8971\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2328 - accuracy: 0.9058\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2089 - accuracy: 0.9164\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2037 - accuracy: 0.9199\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1853 - accuracy: 0.9272\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1663 - accuracy: 0.9354\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.1562 - accuracy: 0.9405\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1535 - accuracy: 0.9416\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1458 - accuracy: 0.9429\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1366 - accuracy: 0.9477\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.1394 - accuracy: 0.9478\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1134 - accuracy: 0.9556\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1140 - accuracy: 0.9560\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1169 - accuracy: 0.9549\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 3s 2ms/step - loss: 0.1005 - accuracy: 0.9615\n",
      "366/366 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9756\n",
      "Test Accuracy for Learning Rate 0.004: 0.9756451845169067\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.005\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.8331 - accuracy: 0.6343\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.4286 - accuracy: 0.8103\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.3645 - accuracy: 0.8373\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3180 - accuracy: 0.8661\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.2722 - accuracy: 0.8894\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2309 - accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2068 - accuracy: 0.9186\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1904 - accuracy: 0.9265\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.1741 - accuracy: 0.9338\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1749 - accuracy: 0.9350\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1531 - accuracy: 0.9427\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1394 - accuracy: 0.9462\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.1369 - accuracy: 0.9487\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1343 - accuracy: 0.9508\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1261 - accuracy: 0.9525\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1114 - accuracy: 0.9584\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1173 - accuracy: 0.9559\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1082 - accuracy: 0.9585\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1082 - accuracy: 0.9591\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.0927 - accuracy: 0.9648\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 0.1351 - accuracy: 0.9574\n",
      "Test Accuracy for Learning Rate 0.005: 0.9574431777000427\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.006\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 5s 3ms/step - loss: 0.7323 - accuracy: 0.6886\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.4458 - accuracy: 0.8060\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3932 - accuracy: 0.8293\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3444 - accuracy: 0.8507\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3201 - accuracy: 0.8642\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2846 - accuracy: 0.8841\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2526 - accuracy: 0.8978\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2370 - accuracy: 0.9048\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2182 - accuracy: 0.9123\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2165 - accuracy: 0.9139\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1963 - accuracy: 0.9238\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1928 - accuracy: 0.9266\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1778 - accuracy: 0.9309\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9296\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1684 - accuracy: 0.9346\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1592 - accuracy: 0.9385\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1543 - accuracy: 0.9410\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1526 - accuracy: 0.9426\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1421 - accuracy: 0.9463\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1441 - accuracy: 0.9460\n",
      "366/366 [==============================] - 2s 4ms/step - loss: 0.1896 - accuracy: 0.9434\n",
      "Test Accuracy for Learning Rate 0.006: 0.9434284567832947\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.007\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.6905 - accuracy: 0.7064\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.4211 - accuracy: 0.8133\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.3950 - accuracy: 0.8285\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3480 - accuracy: 0.8505\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3135 - accuracy: 0.8654\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2896 - accuracy: 0.8800\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.2753 - accuracy: 0.8874\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.2516 - accuracy: 0.8994\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.2272 - accuracy: 0.9117\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.2103 - accuracy: 0.9184\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1876 - accuracy: 0.9272\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.1933 - accuracy: 0.9262\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.1703 - accuracy: 0.9350\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1870 - accuracy: 0.9301\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1525 - accuracy: 0.9426\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1568 - accuracy: 0.9401\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1453 - accuracy: 0.9459\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1431 - accuracy: 0.9477\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1308 - accuracy: 0.9505\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.1356 - accuracy: 0.9497\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9621\n",
      "Test Accuracy for Learning Rate 0.007: 0.9621432423591614\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.008\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.7960 - accuracy: 0.6437\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.4357 - accuracy: 0.8092\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3756 - accuracy: 0.8363\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3712 - accuracy: 0.8395\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 8s 5ms/step - loss: 0.3227 - accuracy: 0.8651\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2982 - accuracy: 0.8789\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2566 - accuracy: 0.8957\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2572 - accuracy: 0.8966\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2206 - accuracy: 0.9108\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2004 - accuracy: 0.9199\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1998 - accuracy: 0.9203\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.1919 - accuracy: 0.9261\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1775 - accuracy: 0.9302\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1646 - accuracy: 0.9366\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1594 - accuracy: 0.9383\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1595 - accuracy: 0.9392\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1643 - accuracy: 0.9365\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 8s 6ms/step - loss: 0.1407 - accuracy: 0.9464\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1381 - accuracy: 0.9469\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1356 - accuracy: 0.9473\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.9603\n",
      "Test Accuracy for Learning Rate 0.008: 0.9603486657142639\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.009000000000000001\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.8047 - accuracy: 0.6434\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.4458 - accuracy: 0.8046\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3826 - accuracy: 0.8309\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.3579 - accuracy: 0.8443\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3285 - accuracy: 0.8601\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2962 - accuracy: 0.8786\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2771 - accuracy: 0.8890\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2593 - accuracy: 0.8982\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2309 - accuracy: 0.9090\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2495 - accuracy: 0.9022\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2077 - accuracy: 0.9184\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2016 - accuracy: 0.9229\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1998 - accuracy: 0.9251\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1914 - accuracy: 0.9267\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1676 - accuracy: 0.9355\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1799 - accuracy: 0.9346\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1715 - accuracy: 0.9363\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1478 - accuracy: 0.9457\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1577 - accuracy: 0.9422\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.1389 - accuracy: 0.9495\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 0.1456 - accuracy: 0.9620\n",
      "Test Accuracy for Learning Rate 0.009000000000000001: 0.9619722962379456\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.7432 - accuracy: 0.6759\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.4393 - accuracy: 0.8040\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3985 - accuracy: 0.8250\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3442 - accuracy: 0.8550\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.3112 - accuracy: 0.8707\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.3071 - accuracy: 0.8747\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2703 - accuracy: 0.8896\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2514 - accuracy: 0.8984\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2411 - accuracy: 0.9042\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 6s 4ms/step - loss: 0.2158 - accuracy: 0.9141\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2032 - accuracy: 0.9184\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.2039 - accuracy: 0.9201\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1991 - accuracy: 0.9234\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1854 - accuracy: 0.9301\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1696 - accuracy: 0.9370\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 7s 4ms/step - loss: 0.1703 - accuracy: 0.9372\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1738 - accuracy: 0.9342\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1491 - accuracy: 0.9442\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 7s 5ms/step - loss: 0.1536 - accuracy: 0.9429\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 5s 4ms/step - loss: 0.1513 - accuracy: 0.9461\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9477\n",
      "Test Accuracy for Learning Rate 0.010000000000000002: 0.9477012753486633\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9500939846038818,\n",
       " 0.9436848163604736,\n",
       " 0.9580413699150085,\n",
       " 0.9756451845169067,\n",
       " 0.9574431777000427,\n",
       " 0.9434284567832947,\n",
       " 0.9621432423591614,\n",
       " 0.9603486657142639,\n",
       " 0.9619722962379456,\n",
       " 0.9477012753486633]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "''' Write a for loop that iterates over learning_rates array which was defined in the previous cell\n",
    "    In each iteration:\n",
    "        build a new model by calling build_model(),\n",
    "        compile with the optimizer of your choice, and the current learning_rate in this iteration,\n",
    "        train on X_train and y_train with 20 epochs,\n",
    "        evaluate the model on X_test, y_test and get the test accuracy,\n",
    "        append the test accuracy to the accuracies list\n",
    "'''\n",
    "for i in learning_rates:\n",
    "    print(\"Current Learning Rate: \" + str(i))\n",
    "    new_model = build_model()\n",
    "    new_model_opt = tf.keras.optimizers.Adam(learning_rate=i)\n",
    "    \n",
    "    new_model.compile(\n",
    "        optimizer=new_model_opt, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    new_model_history = new_model.fit(X_train, y_train, epochs=20)\n",
    "    new_model_loss, new_model_test_accuracy = new_model.evaluate(X_test, y_test)\n",
    "    accuracies.append(new_model_test_accuracy)\n",
    "    print(\"Test Accuracy for Learning Rate \" + str(i) + \": \" + str(new_model_test_accuracy))\n",
    "    print('\\n------------------------------------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Impact of Learning Rate on Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' [20 Points]\n",
    "    Plot the \"Impact of Learning Rate on Accuracy\" with 'Learning Rate' on x-axis and 'Accuracy' on y_axis\n",
    "    The plot should use 'seaborn' style and with a figsize=(10, 5) and fontsize=14 for the title/labels\n",
    "    The plot must have title, axis labels, and xticks precisely as specified and displayed below\n",
    "    \n",
    "    The range of your accuracies may slightly differ but should be similar, and\n",
    "    the range of learning rate should be exactly the same, i.e from 0.001 to 0.01\n",
    "    \n",
    "    Incomplete/wrong plots will get no credit '''\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "title = 'Impact of Learning Rate on Accuracy'\n",
    "x_label = 'Learning Rate'\n",
    "y_label = 'Accuracy'\n",
    "font_size = 14\n",
    "\n",
    "x_axis = learning_rates\n",
    "y_axis = accuracies\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.xticks(learning_rates)\n",
    "chart = sns.lineplot(x = x_axis, y = y_axis, color = 'blue')\n",
    "chart.set_xlabel(x_label, fontsize = font_size)\n",
    "chart.set_ylabel(y_label, fontsize = font_size)\n",
    "chart.set_title(title, fontsize = font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-I - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER THE FOLLOWING QUESTIONS HERE:\n",
    "\n",
    "**Q1 [5 points]** - According to your plot of accuracy vs learning rate, what is a good value for learning rate? **Why**? Mention the reason clearly.\n",
    "\n",
    "Answer: \n",
    "\n",
    "A good value for the learning rate is 0.004. 0.004 results in a noticable difference in accuracy compared to the other values. The accuracies for the model whose optimizer uses a learning rate of 0.004 is significantly higher compared to the accuracies for other learning rates. The other learning rates either make the network converge to the solution too slowly or converge too fast and overfit the data. \n",
    "\n",
    "**Q2 [5 points]** - Name five learning rate scheduling policies known as **learning schedules** (you may consult with the textbook), and explain each briefly in no more than two sentences here.\n",
    "\n",
    "Answer (each policy with explanation has 1 point):\n",
    "\n",
    "1. Power Scheduling </br>\n",
    "The learning rate scales down as the number of iterations increases. Tuning involves tweaking the initial learning rate, the number of steps required before the learning rate is reduced and the power with which the denominator is raised to.\n",
    "\n",
    "\n",
    "2. Exponential Scheduling</br>\n",
    "The learning rate scales down by a scale of pow(initial_LR * 0.1, t/s). This reduces the learning rate by a factor of 10 every s steps - much faster reduction compared to Power Scheduling. \n",
    "\n",
    "\n",
    "3. Piecewise Constant Scheduling</br>\n",
    "Use a constant learning rate for a certain number of epochs and then switch to a progressively lower but constant learning rate as the number of epochs increases. This can work veyr well but can be very tedious to find a correct sequence of learning rates to progress through.\n",
    "\n",
    "\n",
    "4. Performance Scheduling</br>\n",
    "This is similar to early stopping with a constant learning rate; rather than stopping training entirely the learning rate is reduced by a specified amount when the validation error stops decreasing.\n",
    "\n",
    "\n",
    "5. 1cycle Scheduling</br>\n",
    "The learning rate increases linearly to a specified maximum during the first half of training, decreases back to the initial value during the second half; near the end of training the learning rate is dropped dramatically. Momentum scheduling does the opposite: start with the max learning rate, drop to a lower value during first half of training, increase the learning rate to the max value during the second half of training and then maintain this max value for the last training epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-II - Regression Using NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part-II, you're going to perform a regression task using NN that you build in Tensorflow/Keras framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [\"Video Game Sales with Ratings\"](https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings) dataset and read the descriptions on the Kaggle page. You are going to build and train a regression NN to predict **`NA_Sales`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16719, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the 'Video_Games_Sales_as_at_22_Dec_2016.csv' as a dataframe using pandas\n",
    "data2 = pd.read_csv('Video_Games_Sales_as_at_22_Dec_2016.csv')\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the multiple steps of preprocessing very carefully.\n",
    "\n",
    "**NOTE**: If you do not perform the preprocessing steps correctly, all of your results would be wrong and your Part-II will get zero points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As usual, check if there is any NAs (there are plenty) and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  2\n",
       "Platform              0\n",
       "Year_of_Release     269\n",
       "Genre                 2\n",
       "Publisher            54\n",
       "NA_Sales              0\n",
       "EU_Sales              0\n",
       "JP_Sales              0\n",
       "Other_Sales           0\n",
       "Global_Sales          0\n",
       "Critic_Score       8582\n",
       "Critic_Count       8582\n",
       "User_Score         6704\n",
       "User_Count         9129\n",
       "Developer          6623\n",
       "Rating             6769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NAs\n",
    "data2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Super Mario Bros.</td>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii Play</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Platform  Year_of_Release     Genre Publisher  \\\n",
       "0             Wii Sports      Wii           2006.0    Sports  Nintendo   \n",
       "2         Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
       "3      Wii Sports Resort      Wii           2009.0    Sports  Nintendo   \n",
       "6  New Super Mario Bros.       DS           2006.0  Platform  Nintendo   \n",
       "7               Wii Play      Wii           2006.0      Misc  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "6     11.28      9.14      6.50         2.88         29.80          89.0   \n",
       "7     13.96      9.18      2.93         2.84         28.92          58.0   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "6          65.0        8.5       431.0  Nintendo      E  \n",
       "7          41.0        6.6       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NAs\n",
    "data2 = data2.dropna()\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Platform           0\n",
       "Year_of_Release    0\n",
       "Genre              0\n",
       "Publisher          0\n",
       "NA_Sales           0\n",
       "EU_Sales           0\n",
       "JP_Sales           0\n",
       "Other_Sales        0\n",
       "Global_Sales       0\n",
       "Critic_Score       0\n",
       "Critic_Count       0\n",
       "User_Score         0\n",
       "User_Count         0\n",
       "Developer          0\n",
       "Rating             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NAs again\n",
    "data2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since there were a lot of NAs, you've missed a lot of indexes of the dropped rows after dropping NAs, so you should use [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) but no new column should be added as `index`, so you should set the `drop` parameter of `reset_index()` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Super Mario Bros.</td>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii Play</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Platform  Year_of_Release     Genre Publisher  \\\n",
       "0             Wii Sports      Wii           2006.0    Sports  Nintendo   \n",
       "2         Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
       "3      Wii Sports Resort      Wii           2009.0    Sports  Nintendo   \n",
       "6  New Super Mario Bros.       DS           2006.0  Platform  Nintendo   \n",
       "7               Wii Play      Wii           2006.0      Misc  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "6     11.28      9.14      6.50         2.88         29.80          89.0   \n",
       "7     13.96      9.18      2.93         2.84         28.92          58.0   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "6          65.0        8.5       431.0  Nintendo      E  \n",
       "7          41.0        6.6       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index so that the rows are indexed from 0 and increment by one, no column should be added!\n",
    "data2.reset_index(drop=True)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     41.36     28.96      3.77   \n",
       "2      Wii           2008.0    Racing  Nintendo     15.68     12.76      3.79   \n",
       "3      Wii           2009.0    Sports  Nintendo     15.61     10.93      3.28   \n",
       "6       DS           2006.0  Platform  Nintendo     11.28      9.14      6.50   \n",
       "7      Wii           2006.0      Misc  Nintendo     13.96      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Global_Sales  Critic_Score  Critic_Count User_Score  \\\n",
       "0         8.45         82.53          76.0          51.0          8   \n",
       "2         3.29         35.52          82.0          73.0        8.3   \n",
       "3         2.95         32.77          80.0          73.0          8   \n",
       "6         2.88         29.80          89.0          65.0        8.5   \n",
       "7         2.84         28.92          58.0          41.0        6.6   \n",
       "\n",
       "   User_Count Developer Rating  \n",
       "0       322.0  Nintendo      E  \n",
       "2       709.0  Nintendo      E  \n",
       "3       192.0  Nintendo      E  \n",
       "6       431.0  Nintendo      E  \n",
       "7       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Name\" column as it does not provide useful info for your model training\n",
    "data2 = data2.drop('Name', axis=1)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `NA_Sales` is the target column for prediction; however, since the column `Global_Sales` is the sum of other sales, you should drop it; otherwise, it corrupts the training process by leaking information and violating the regression assumption that features are independent.\n",
    "\n",
    "> **NOTE**: Make sure to match your `data2` dataframe with the provided outputs after every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     41.36     28.96      3.77   \n",
       "2      Wii           2008.0    Racing  Nintendo     15.68     12.76      3.79   \n",
       "3      Wii           2009.0    Sports  Nintendo     15.61     10.93      3.28   \n",
       "6       DS           2006.0  Platform  Nintendo     11.28      9.14      6.50   \n",
       "7      Wii           2006.0      Misc  Nintendo     13.96      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Critic_Score  Critic_Count User_Score  User_Count Developer  \\\n",
       "0         8.45          76.0          51.0          8       322.0  Nintendo   \n",
       "2         3.29          82.0          73.0        8.3       709.0  Nintendo   \n",
       "3         2.95          80.0          73.0          8       192.0  Nintendo   \n",
       "6         2.88          89.0          65.0        8.5       431.0  Nintendo   \n",
       "7         2.84          58.0          41.0        6.6       129.0  Nintendo   \n",
       "\n",
       "  Rating  \n",
       "0      E  \n",
       "2      E  \n",
       "3      E  \n",
       "6      E  \n",
       "7      E  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Global_Sales\" column\n",
    "data2 = data2.drop('Global_Sales', axis=1)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, check the statistical description of `NA_Sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6825.000000\n",
       "mean        0.394484\n",
       "std         0.967385\n",
       "min         0.000000\n",
       "25%         0.060000\n",
       "50%         0.150000\n",
       "75%         0.390000\n",
       "max        41.360000\n",
       "Name: NA_Sales, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['NA_Sales'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year_of_Release   -0.016239\n",
       "Critic_Score       0.233580\n",
       "User_Count         0.246208\n",
       "Critic_Count       0.283917\n",
       "JP_Sales           0.468607\n",
       "Other_Sales        0.726757\n",
       "EU_Sales           0.841808\n",
       "NA_Sales           1.000000\n",
       "Name: NA_Sales, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find correlations with NA_Sales\n",
    "correlations = data2.corr()[\"NA_Sales\"].sort_values()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate features from the target column, so `X2` should contain all columns except `NA_Sales`. `y2` should contain `NA_Sales` only. `X2` and `y2` are so named to differentiate them from the features and labels of Part-I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature vector X2 (all columns but \"NA_Sales\") and target label y2 as \"NA_Sales\"\n",
    "X2 = data2.drop('NA_Sales', axis=1)\n",
    "y2 = data2['NA_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     28.96      3.77   \n",
       "2      Wii           2008.0    Racing  Nintendo     12.76      3.79   \n",
       "3      Wii           2009.0    Sports  Nintendo     10.93      3.28   \n",
       "6       DS           2006.0  Platform  Nintendo      9.14      6.50   \n",
       "7      Wii           2006.0      Misc  Nintendo      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Critic_Score  Critic_Count User_Score  User_Count Developer  \\\n",
       "0         8.45          76.0          51.0          8       322.0  Nintendo   \n",
       "2         3.29          82.0          73.0        8.3       709.0  Nintendo   \n",
       "3         2.95          80.0          73.0          8       192.0  Nintendo   \n",
       "6         2.88          89.0          65.0        8.5       431.0  Nintendo   \n",
       "7         2.84          58.0          41.0        6.6       129.0  Nintendo   \n",
       "\n",
       "  Rating  \n",
       "0      E  \n",
       "2      E  \n",
       "3      E  \n",
       "6      E  \n",
       "7      E  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print X2 shape and head\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    41.36\n",
       "2    15.68\n",
       "3    15.61\n",
       "6    11.28\n",
       "7    13.96\n",
       "Name: NA_Sales, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print y2 shape and head\n",
    "print(y2.shape)\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You should convert `object` (categorical) features, and there are multiple strategies for encoding categorical features. The right choice depends on the feature and number of unique values it has. Below you see some of those strategies applied on different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform            object\n",
       "Year_of_Release    float64\n",
       "Genre               object\n",
       "Publisher           object\n",
       "EU_Sales           float64\n",
       "JP_Sales           float64\n",
       "Other_Sales        float64\n",
       "Critic_Score       float64\n",
       "Critic_Count       float64\n",
       "User_Score          object\n",
       "User_Count         float64\n",
       "Developer           object\n",
       "Rating              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since `Developer` is categorical, we should encode it. The issue is that it has 1289 unique values, so **one-hot encoding** is not a good choice due to **curse of dimensionality**. Also, the categorical values have no ranking, meaning `Developer` is a **nominal variable**; thus, **Label Encoding** is NOT a good choice either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.Developer.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Frequency Encoding** seems a good choice for `Developer` although we definitely lose some information, but still it's better than **One-Hot Encoding** and **Label Encoding** for this particular feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = X2.Developer.value_counts().to_frame()\n",
    "val_counts.rename(columns={\"vendor_name\": \"count\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Developer</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EA Canada</th>\n",
       "      <td>149</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EA Sports</th>\n",
       "      <td>142</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capcom</th>\n",
       "      <td>126</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ubisoft</th>\n",
       "      <td>103</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Konami</th>\n",
       "      <td>95</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sanzaru Games, Sanzaru Games, Inc.</th>\n",
       "      <td>1</td>\n",
       "      <td>784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCEA, Think and Feel</th>\n",
       "      <td>1</td>\n",
       "      <td>784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ubisoft Annecy</th>\n",
       "      <td>1</td>\n",
       "      <td>784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega Force, Koei Canada</th>\n",
       "      <td>1</td>\n",
       "      <td>784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atomic Games</th>\n",
       "      <td>1</td>\n",
       "      <td>784.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1289 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Developer   rank\n",
       "EA Canada                                 149    1.0\n",
       "EA Sports                                 142    2.0\n",
       "Capcom                                    126    3.0\n",
       "Ubisoft                                   103    4.0\n",
       "Konami                                     95    5.0\n",
       "...                                       ...    ...\n",
       "Sanzaru Games, Sanzaru Games, Inc.          1  784.0\n",
       "SCEA, Think and Feel                        1  784.0\n",
       "Ubisoft Annecy                              1  784.0\n",
       "Omega Force, Koei Canada                    1  784.0\n",
       "Atomic Games                                1  784.0\n",
       "\n",
       "[1289 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_counts['rank'] = pd.Series(X2.Developer.value_counts().rank(method='min', ascending=False))\n",
    "val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Developer_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>6.94</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.24</td>\n",
       "      <td>87.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>594.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DS</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>7.47</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.90</td>\n",
       "      <td>91.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>464.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>8.03</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.15</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>146.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X360</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.69</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>8.49</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>E</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Platform  Year_of_Release     Genre               Publisher  EU_Sales  \\\n",
       "0       Wii           2006.0    Sports                Nintendo     28.96   \n",
       "2       Wii           2008.0    Racing                Nintendo     12.76   \n",
       "3       Wii           2009.0    Sports                Nintendo     10.93   \n",
       "6        DS           2006.0  Platform                Nintendo      9.14   \n",
       "7       Wii           2006.0      Misc                Nintendo      9.18   \n",
       "8       Wii           2009.0  Platform                Nintendo      6.94   \n",
       "11       DS           2005.0    Racing                Nintendo      7.47   \n",
       "13      Wii           2007.0    Sports                Nintendo      8.03   \n",
       "14     X360           2010.0      Misc  Microsoft Game Studios      4.89   \n",
       "15      Wii           2009.0    Sports                Nintendo      8.49   \n",
       "\n",
       "    JP_Sales  Other_Sales  Critic_Score  Critic_Count User_Score  User_Count  \\\n",
       "0       3.77         8.45          76.0          51.0          8       322.0   \n",
       "2       3.79         3.29          82.0          73.0        8.3       709.0   \n",
       "3       3.28         2.95          80.0          73.0          8       192.0   \n",
       "6       6.50         2.88          89.0          65.0        8.5       431.0   \n",
       "7       2.93         2.84          58.0          41.0        6.6       129.0   \n",
       "8       4.70         2.24          87.0          80.0        8.4       594.0   \n",
       "11      4.13         1.90          91.0          64.0        8.6       464.0   \n",
       "13      3.60         2.15          80.0          63.0        7.7       146.0   \n",
       "14      0.24         1.69          61.0          45.0        6.3       106.0   \n",
       "15      2.53         1.77          80.0          33.0        7.4        52.0   \n",
       "\n",
       "   Rating  Developer_freq  \n",
       "0       E              68  \n",
       "2       E              68  \n",
       "3       E              68  \n",
       "6       E              68  \n",
       "7       E              68  \n",
       "8       E              68  \n",
       "11      E              68  \n",
       "13      E              68  \n",
       "14      E               1  \n",
       "15      E              68  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping by frequency\n",
    "fq = X2.groupby('Developer').size()\n",
    "# mapping values to X2\n",
    "X2.loc[:, \"{}_freq\".format('Developer')] = X2['Developer'].map(fq)\n",
    "# drop original column\n",
    "X2 = X2.drop(['Developer'], axis = 1)\n",
    "X2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.Developer_freq.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, using the same method as `Developer`, you should convert the following `object` (categorical) features: `Genre`, `Publisher`, `Platform`, and `Rating` using **Frequency Encoding**. We'll encode `User_Score` and `Year_of_Release` later using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer_freq</th>\n",
       "      <th>Genre_freq</th>\n",
       "      <th>Publisher_freq</th>\n",
       "      <th>Platform_freq</th>\n",
       "      <th>Rating_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>68</td>\n",
       "      <td>943</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>68</td>\n",
       "      <td>581</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>68</td>\n",
       "      <td>943</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>68</td>\n",
       "      <td>403</td>\n",
       "      <td>291</td>\n",
       "      <td>464</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>68</td>\n",
       "      <td>384</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release  EU_Sales  JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0           2006.0     28.96      3.77         8.45          76.0   \n",
       "2           2008.0     12.76      3.79         3.29          82.0   \n",
       "3           2009.0     10.93      3.28         2.95          80.0   \n",
       "6           2006.0      9.14      6.50         2.88          89.0   \n",
       "7           2006.0      9.18      2.93         2.84          58.0   \n",
       "\n",
       "   Critic_Count User_Score  User_Count  Developer_freq  Genre_freq  \\\n",
       "0          51.0          8       322.0              68         943   \n",
       "2          73.0        8.3       709.0              68         581   \n",
       "3          73.0          8       192.0              68         943   \n",
       "6          65.0        8.5       431.0              68         403   \n",
       "7          41.0        6.6       129.0              68         384   \n",
       "\n",
       "   Publisher_freq  Platform_freq  Rating_freq  \n",
       "0             291            479         2082  \n",
       "2             291            479         2082  \n",
       "3             291            479         2082  \n",
       "6             291            464         2082  \n",
       "7             291            479         2082  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the rest of the categorical features by their frequency\n",
    "fq1 = X2.groupby('Genre').size()\n",
    "fq2 = X2.groupby('Publisher').size()\n",
    "fq3 = X2.groupby('Platform').size()\n",
    "fq4 = X2.groupby('Rating').size()\n",
    "\n",
    "# Create columns in X2 for the encoded values of the features\n",
    "X2.loc[:, '{}_freq'.format('Genre')] = X2['Genre'].map(fq1)\n",
    "X2.loc[:, '{}_freq'.format('Publisher')] = X2['Publisher'].map(fq2)\n",
    "X2.loc[:, '{}_freq'.format('Platform')] = X2['Platform'].map(fq3)\n",
    "X2.loc[:, '{}_freq'.format('Rating')] = X2['Rating'].map(fq4)\n",
    "\n",
    "#No need for non-encoded columns, drop them all\n",
    "X2 = X2.drop(['Genre', 'Publisher', 'Platform', 'Rating'], axis=1)\n",
    "\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year_of_Release    float64\n",
       "EU_Sales           float64\n",
       "JP_Sales           float64\n",
       "Other_Sales        float64\n",
       "Critic_Score       float64\n",
       "Critic_Count       float64\n",
       "User_Score          object\n",
       "User_Count         float64\n",
       "Developer_freq       int64\n",
       "Genre_freq           int64\n",
       "Publisher_freq       int64\n",
       "Platform_freq        int64\n",
       "Rating_freq          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `User_score` is already numeric, so we just need to convert it to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer_freq</th>\n",
       "      <th>Genre_freq</th>\n",
       "      <th>Publisher_freq</th>\n",
       "      <th>Platform_freq</th>\n",
       "      <th>Rating_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>68</td>\n",
       "      <td>943</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>68</td>\n",
       "      <td>581</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>68</td>\n",
       "      <td>943</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>68</td>\n",
       "      <td>403</td>\n",
       "      <td>291</td>\n",
       "      <td>464</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>68</td>\n",
       "      <td>384</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release  EU_Sales  JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0           2006.0     28.96      3.77         8.45          76.0   \n",
       "2           2008.0     12.76      3.79         3.29          82.0   \n",
       "3           2009.0     10.93      3.28         2.95          80.0   \n",
       "6           2006.0      9.14      6.50         2.88          89.0   \n",
       "7           2006.0      9.18      2.93         2.84          58.0   \n",
       "\n",
       "   Critic_Count  User_Score  User_Count  Developer_freq  Genre_freq  \\\n",
       "0          51.0         8.0       322.0              68         943   \n",
       "2          73.0         8.3       709.0              68         581   \n",
       "3          73.0         8.0       192.0              68         943   \n",
       "6          65.0         8.5       431.0              68         403   \n",
       "7          41.0         6.6       129.0              68         384   \n",
       "\n",
       "   Publisher_freq  Platform_freq  Rating_freq  \n",
       "0             291            479         2082  \n",
       "2             291            479         2082  \n",
       "3             291            479         2082  \n",
       "6             291            464         2082  \n",
       "7             291            479         2082  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2['User_Score'] = X2['User_Score'].astype(float)\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Year_of_Release` is an **Ordinal** feature, so we can use **Ordinal Encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2006., 2008., 2009., 2005., 2007., 2010., 2013., 2004., 2002.,\n",
       "       2001., 2011., 2012., 2014., 1997., 1999., 2015., 2016., 2003.,\n",
       "       1998., 1996., 2000., 1994., 1985., 1992., 1988.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.Year_of_Release.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer_freq</th>\n",
       "      <th>Genre_freq</th>\n",
       "      <th>Publisher_freq</th>\n",
       "      <th>Platform_freq</th>\n",
       "      <th>Rating_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>68</td>\n",
       "      <td>943</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>68</td>\n",
       "      <td>581</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>68</td>\n",
       "      <td>943</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>68</td>\n",
       "      <td>403</td>\n",
       "      <td>291</td>\n",
       "      <td>464</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>68</td>\n",
       "      <td>384</td>\n",
       "      <td>291</td>\n",
       "      <td>479</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release  EU_Sales  JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0             14.0     28.96      3.77         8.45          76.0   \n",
       "2             16.0     12.76      3.79         3.29          82.0   \n",
       "3             17.0     10.93      3.28         2.95          80.0   \n",
       "6             14.0      9.14      6.50         2.88          89.0   \n",
       "7             14.0      9.18      2.93         2.84          58.0   \n",
       "\n",
       "   Critic_Count  User_Score  User_Count  Developer_freq  Genre_freq  \\\n",
       "0          51.0         8.0       322.0              68         943   \n",
       "2          73.0         8.3       709.0              68         581   \n",
       "3          73.0         8.0       192.0              68         943   \n",
       "6          65.0         8.5       431.0              68         403   \n",
       "7          41.0         6.6       129.0              68         384   \n",
       "\n",
       "   Publisher_freq  Platform_freq  Rating_freq  \n",
       "0             291            479         2082  \n",
       "2             291            479         2082  \n",
       "3             291            479         2082  \n",
       "6             291            464         2082  \n",
       "7             291            479         2082  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to import the required module at the top in the import cell\n",
    "ord_enc = OrdinalEncoder()\n",
    "X2[\"Year_of_Release\"] = ord_enc.fit_transform(X2[[\"Year_of_Release\"]])\n",
    "\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year_of_Release    float64\n",
       "EU_Sales           float64\n",
       "JP_Sales           float64\n",
       "Other_Sales        float64\n",
       "Critic_Score       float64\n",
       "Critic_Count       float64\n",
       "User_Score         float64\n",
       "User_Count         float64\n",
       "Developer_freq       int64\n",
       "Genre_freq           int64\n",
       "Publisher_freq       int64\n",
       "Platform_freq        int64\n",
       "Rating_freq          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer_freq</th>\n",
       "      <th>Genre_freq</th>\n",
       "      <th>Publisher_freq</th>\n",
       "      <th>Platform_freq</th>\n",
       "      <th>Rating_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.342432</td>\n",
       "      <td>41.790569</td>\n",
       "      <td>12.886767</td>\n",
       "      <td>31.004904</td>\n",
       "      <td>0.413014</td>\n",
       "      <td>1.147975</td>\n",
       "      <td>0.565560</td>\n",
       "      <td>0.250716</td>\n",
       "      <td>1.061933</td>\n",
       "      <td>0.182752</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.478813</td>\n",
       "      <td>0.371918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133507</td>\n",
       "      <td>18.221103</td>\n",
       "      <td>12.956315</td>\n",
       "      <td>11.884655</td>\n",
       "      <td>0.845647</td>\n",
       "      <td>2.292368</td>\n",
       "      <td>0.773902</td>\n",
       "      <td>0.909519</td>\n",
       "      <td>1.061933</td>\n",
       "      <td>-0.556046</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.478813</td>\n",
       "      <td>0.371918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.371476</td>\n",
       "      <td>15.558627</td>\n",
       "      <td>11.182831</td>\n",
       "      <td>10.624793</td>\n",
       "      <td>0.701436</td>\n",
       "      <td>2.292368</td>\n",
       "      <td>0.565560</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.061933</td>\n",
       "      <td>0.182752</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.478813</td>\n",
       "      <td>0.371918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.342432</td>\n",
       "      <td>12.954346</td>\n",
       "      <td>22.380122</td>\n",
       "      <td>10.365410</td>\n",
       "      <td>1.350385</td>\n",
       "      <td>1.876225</td>\n",
       "      <td>0.912796</td>\n",
       "      <td>0.436270</td>\n",
       "      <td>1.061933</td>\n",
       "      <td>-0.919323</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.526587</td>\n",
       "      <td>0.371918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.342432</td>\n",
       "      <td>13.012543</td>\n",
       "      <td>9.965734</td>\n",
       "      <td>10.217191</td>\n",
       "      <td>-0.884885</td>\n",
       "      <td>0.627797</td>\n",
       "      <td>-0.406701</td>\n",
       "      <td>-0.077835</td>\n",
       "      <td>1.061933</td>\n",
       "      <td>-0.958100</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.478813</td>\n",
       "      <td>0.371918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release   EU_Sales   JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0        -0.342432  41.790569  12.886767    31.004904      0.413014   \n",
       "2         0.133507  18.221103  12.956315    11.884655      0.845647   \n",
       "3         0.371476  15.558627  11.182831    10.624793      0.701436   \n",
       "6        -0.342432  12.954346  22.380122    10.365410      1.350385   \n",
       "7        -0.342432  13.012543   9.965734    10.217191     -0.884885   \n",
       "\n",
       "   Critic_Count  User_Score  User_Count  Developer_freq  Genre_freq  \\\n",
       "0      1.147975    0.565560    0.250716        1.061933    0.182752   \n",
       "2      2.292368    0.773902    0.909519        1.061933   -0.556046   \n",
       "3      2.292368    0.565560    0.029412        1.061933    0.182752   \n",
       "6      1.876225    0.912796    0.436270        1.061933   -0.919323   \n",
       "7      0.627797   -0.406701   -0.077835        1.061933   -0.958100   \n",
       "\n",
       "   Publisher_freq  Platform_freq  Rating_freq  \n",
       "0       -0.093788      -0.478813     0.371918  \n",
       "2       -0.093788      -0.478813     0.371918  \n",
       "3       -0.093788      -0.478813     0.371918  \n",
       "6       -0.093788      -0.526587     0.371918  \n",
       "7       -0.093788      -0.478813     0.371918  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize X2 using X2.mean() and X2.std()  NOTE: The output is provided for your reference.\n",
    "# Formula to normalize (0 mean, 1 std): z = [x - x.mean()] / [x.std()]\n",
    "X2 = (X2 - X2.mean())/X2.std()\n",
    "\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5460, 13)\n",
      "(5460,)\n",
      "(1365, 13)\n",
      "(1365,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to train and test with ratio of 80/20 for train/test respectively\n",
    "# NOTE: Make sure to split X2 and y2, NOT X and y!\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "print(X2_train.shape)\n",
    "print(y2_train.shape)\n",
    "print(X2_test.shape)\n",
    "print(y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building NN for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a sequential NN model `nn_reg` with proper configurations for the regression task.\n",
    "\n",
    "> **Hints**:\n",
    "> - `input_dim` of the first layer should match with the number of features in `X2`\n",
    "\n",
    "> - ReLU is usually a good activation function for the hidden layers, but you may also try other activation functions and/or initialization strategies.\n",
    "\n",
    "> - Note that the activation function and number of neurons in the output layer are determined by the type of ML task i.e. Regression. Also note that there is no limit/restriction defined on the predicted value `NA_Sales`. As mentioned in the lectures, you should NOT modify/amend the problem defintion and your neural network should precisely match with the ML task specifications, which in this case is **a regression task with an unbounded output**.\n",
    "\n",
    "> - The common loss functions for regression are `mae` and `mse` and the metric is usually the same as loss for regression. To keep the results consistent with the requirements, you should use `mae` as the loss function, and the metric would also be `mae`.\n",
    "\n",
    "> - You're going to use callback and early stopping to determine the optimal number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='red'>**Test MAE Loss Requirement**</font>: Your `nn_reg` model's `mae` loss on `X2_test` should not exceed **0.20**, i.e. the test `mae` loss should be 0.20 or lower. Otherwise, your `nn_reg` will get zero points for this part, so you must fine-tune your `nn_reg` and `compile` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build nn_reg with appropriate layers for regression\n",
    "\n",
    "    Hint1: input_dim of the first layer should match with the number of features in X2\n",
    "    \n",
    "    Hint2: The activation function and number of neurons in the output layer are determined\n",
    "    by the type of ML task i.e. Regression\n",
    "    \n",
    "    Hint3: If you observed overfitting in the history plot,\n",
    "    consider using regularization techniques such as Dropout, and/or Batch Normalization '''\n",
    "\n",
    "# nn_reg_callbacks = nn_reg_callback()\n",
    "\n",
    "# Unbounded output = no activation function on output layer\n",
    "# Predicting one value so output layer has 1 neuron (No activation function dumbass!!)\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=None)\n",
    "\n",
    "nn_reg_hidden1 = keras.layers.Dense(13, input_shape=(13,), activation='relu', kernel_initializer=initializer)\n",
    "nn_reg_hidden2 = keras.layers.Dense(13, activation='relu', kernel_initializer=initializer)\n",
    "nn_reg_output = keras.layers.Dense(1, activation=None)\n",
    "\n",
    "\n",
    "nn_reg = keras.Sequential([\n",
    "    nn_reg_hidden1,\n",
    "    nn_reg_hidden2,\n",
    "    nn_reg_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer of your choice and set its learning_rate (you may need to tune it)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.003, rho = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, you're going to create `callbacks` and `EarlyStopping`.\n",
    "\n",
    "> **Note:** The `patience` parameter is the number of epochs to monitor for improvement in `EarlyStopping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a callback with EarlyStopping and,\n",
    "    monitor='val_loss',  patience=10 and restore_best_weights=True '''\n",
    "\n",
    "early_stopping_reg = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Compile nn_reg with loss='mae', optimizer=optimizer and metrics=['mae'] '''\n",
    "nn_reg.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mae',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now run the training, sit back and let tf/keras determine the optimal number of epochs! Although the `EPOCHS` is set to 200, the training would usually stop sooner with `EarlyStopping`. You may change/increase `EPOCHS` and/or any other `compile` or `nn_reg` hyperparameter that is necessary to achieve the required test `mae` loss, i.e. 0.2 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3598 - mae: 0.3598 - val_loss: 0.2310 - val_mae: 0.2310\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2243 - mae: 0.2243 - val_loss: 0.2126 - val_mae: 0.2126\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2094 - mae: 0.2094 - val_loss: 0.1888 - val_mae: 0.1888\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2012 - mae: 0.2012 - val_loss: 0.1845 - val_mae: 0.1845\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1952 - mae: 0.1952 - val_loss: 0.1839 - val_mae: 0.1839\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1915 - mae: 0.1915 - val_loss: 0.1822 - val_mae: 0.1822\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1865 - mae: 0.1865 - val_loss: 0.1731 - val_mae: 0.1731\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.1676 - val_mae: 0.1676\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.1815 - mae: 0.1815 - val_loss: 0.1701 - val_mae: 0.1701\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1783 - mae: 0.1783 - val_loss: 0.1658 - val_mae: 0.1658\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1778 - mae: 0.1778 - val_loss: 0.1671 - val_mae: 0.1671\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1755 - mae: 0.1755 - val_loss: 0.1589 - val_mae: 0.1589\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.1750 - mae: 0.1750 - val_loss: 0.1633 - val_mae: 0.1633\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1722 - mae: 0.1722 - val_loss: 0.1632 - val_mae: 0.1632\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1718 - mae: 0.1718 - val_loss: 0.1668 - val_mae: 0.1668\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1707 - mae: 0.1707 - val_loss: 0.1665 - val_mae: 0.1665\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1696 - mae: 0.1696 - val_loss: 0.1592 - val_mae: 0.1592\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1579 - val_mae: 0.1579\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1691 - mae: 0.1691 - val_loss: 0.1590 - val_mae: 0.1590\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1652 - mae: 0.1652 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1654 - mae: 0.1654 - val_loss: 0.1634 - val_mae: 0.1634\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1643 - mae: 0.1643 - val_loss: 0.1586 - val_mae: 0.1586\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1625 - mae: 0.1625 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1625 - mae: 0.1625 - val_loss: 0.1575 - val_mae: 0.1575\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.1560 - val_mae: 0.1560\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1617 - mae: 0.1617 - val_loss: 0.1644 - val_mae: 0.1644\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1580 - val_mae: 0.1580\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1593 - mae: 0.1593 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1539 - val_mae: 0.1539\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.1575 - mae: 0.1575 - val_loss: 0.1544 - val_mae: 0.1544\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1570 - mae: 0.1570 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1571 - mae: 0.1571 - val_loss: 0.1490 - val_mae: 0.1490\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1567 - mae: 0.1567 - val_loss: 0.1476 - val_mae: 0.1476\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1566 - mae: 0.1566 - val_loss: 0.1523 - val_mae: 0.1523\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1546 - mae: 0.1546 - val_loss: 0.1509 - val_mae: 0.1509\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.1560 - val_mae: 0.1560\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.1475 - val_mae: 0.1475\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1522 - mae: 0.1522 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1496 - mae: 0.1496 - val_loss: 0.1546 - val_mae: 0.1546\n",
      "Epoch 42/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1515 - mae: 0.1515 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 43/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1504 - mae: 0.1504 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 44/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1506 - mae: 0.1506 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 45/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1504 - mae: 0.1504 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 46/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 47/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1491 - mae: 0.1491 - val_loss: 0.1435 - val_mae: 0.1435\n",
      "Epoch 48/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1484 - mae: 0.1484 - val_loss: 0.1521 - val_mae: 0.1521\n",
      "Epoch 49/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1481 - mae: 0.1481 - val_loss: 0.1424 - val_mae: 0.1424\n",
      "Epoch 50/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1487 - mae: 0.1487 - val_loss: 0.1392 - val_mae: 0.1392\n",
      "Epoch 51/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1477 - mae: 0.1477 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 52/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1486 - mae: 0.1486 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 53/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1462 - mae: 0.1462 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 54/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1458 - mae: 0.1458 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 55/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1440 - mae: 0.1440 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 56/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.1429 - mae: 0.1429 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 57/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.1384 - val_mae: 0.1384\n",
      "Epoch 58/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 59/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1434 - mae: 0.1434 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 60/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1444 - mae: 0.1444 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 61/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1419 - mae: 0.1419 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 63/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.1422 - mae: 0.1422 - val_loss: 0.1448 - val_mae: 0.1448\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "''' Fit nn_reg on X2_train, y2_train, and with epochs=EPOCHS, callbacks=[early_stopping_reg], and\n",
    "    validation_split=0.1 '''\n",
    "nn_reg_history = nn_reg.fit(X2_train, y2_train, epochs=EPOCHS, callbacks=[early_stopping_reg], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot the history with a figsize of (10,5)\n",
    "    the plot style should be reset back to 'default'\n",
    "    the plot should display the grid and the whole range of values for loss and mae '''\n",
    "pd.DataFrame(nn_reg_history.history).plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1801 - mae: 0.1801\n",
      "MAE: 0.18013273179531097\n",
      "Loss is less than 0.2, test passed!\n"
     ]
    }
   ],
   "source": [
    "''' Maximum reg_loss: 0.20 \n",
    "    if reg_loss is higher than 0.2, you should rebuild your nn_reg with new hyperparameters and retrain it '''\n",
    "\n",
    "# Evaluate nn_reg on X2_test, y2_test\n",
    "reg_loss, reg_mae = nn_reg.evaluate(X2_test, y2_test)\n",
    "print(\"MAE: \" + str(reg_mae))\n",
    "\n",
    "if reg_loss and reg_mae < 0.2:  # Sanity check on getting correct test loss \n",
    "    print(\"Loss is less than 0.2, test passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips To Overcome Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the provided `nn_reg_history` plot, it seems there is no severe overfitting because `mae` and `val_mae` are decreasing almost at the same rate. That's because regularization techniques have been used in building `nn_reg`, so you should probably use techniques like batch norm and dropout too, although the beauty of the NNs is that they are so flexible and there might be multiple solutions/architectures that work for a given problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NNs are so prone to overfitting because they have lots of trainable parameters and hence a large degree of freedom which makes them have a high variance.\n",
    "\n",
    "> As discussed in the lectures, there are various regularization techniques to tackle overfitting in NNs and DNNs. You've already used one regularization technique so far in training `nn_reg` and that was `EarlyStopping`. However, if you notice in your history plot that your model has run into overfitting, consider using other techniques, such as `l2`, `Dropout` and `BatchNormalization`. Recall that although `BatchNormalization` was intended to help with unstable gradients problem, it has regularization effects too.\n",
    "\n",
    "> If you want to use both `Dropout` and `BatchNormalization`, it's easier to use them in the order as in the following cell, i.e. first the dense layer with activation function followed by batch norm followed by dropout, although as discussed in the lectures, BN can be applied before the activation function too. You should certainly fine-tune the probability of `Dropout` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3565377274.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [68]\u001b[0;36m\u001b[0m\n\u001b[0;31m    ...\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " ''' Do NOT write anything in this cell!\n",
    "     This is just to show you how to use BN and dropout together'''\n",
    "    ...\n",
    "    tf.keras.layers.Dense(10, activation = \"relu\"), # this is just an example, your dense layers might differ\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2), # dropout probability = 0.2 which may be tuned\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-II - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER THE FOLLOWING QUESTIONS HERE:\n",
    "\n",
    "**Q3 [5 points]** <br>\n",
    "(**a - 3 points**) - Using eraly stopping and callbacks, how may epochs did the training run for `nn_reg`? Find the attribute in `nn_reg_history` object that logs the number of epochs. Write the code to get number of epochs in the following cell.\n",
    "\n",
    "Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epochs used for training: 63\n"
     ]
    }
   ],
   "source": [
    "''' Get the number of epochs from nn_reg_history object\n",
    "    Hint: You should use an attribute of the `history` object that gets the list of all epochs,\n",
    "    and report its length; number of epochs may vary, dependeing on when EarlyStopping stopped training\n",
    "    '''\n",
    "total_epochs = nn_reg_history.history['loss']\n",
    "\n",
    "print('Total epochs used for training: ' + str(len(total_epochs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**b - 2 points**) - How did the training of `nn_reg` stop? Your answer should exactly mention the criteria for when the training stops given the specifications. EXPLAIN CLEARLY AND COMPLETELY IN A FEW SENTENCES.\n",
    "\n",
    "Answer: \n",
    "\n",
    "The training stopped because the amount of measured improvement of the loss over a certain amount of epochs (eg. the patience hyperparameter) did not meet a baseline value for 10 continuous epochs. If the MAE were to have went beyond this mentioned baseline value within 10 epochs then the training would have continued for at least another 10 epochs before having the possibility of terminating early again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4 [5 points]** - On the history plot of `nn_reg`, you have four colors displayed in the legend, but you can see only two of them (only the orange and red curves are displayed). Explain why?\n",
    "\n",
    "Answer: \n",
    "\n",
    "There are only two lines displayed on the graph because MAE is both a metric and a loss function for regression. Plotting both the loss and MAE is plotting the same graph twice - they are essentially perfectly overlapping on the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Assignment-4 has a maximum of 100 points. Make sure that you get the correct outputs/plots for all cells that you implement and give complete answers to all questions. Also, your notebook should be written with no grammatical and spelling errors and should be easy-to-read.\n",
    "\n",
    "The breakdown of the 100 points is as follows:\n",
    "\n",
    "- Part-I Multi-Class Classification: [total 50 points]\n",
    "    - Implementation of `baseline_model`: 10 points - **val_accuracy Requirement**: 0.85 after the last epoch otherwise zero points\n",
    "    - Implementation of `nn_clf`: 10 points - **Test Accuracy Requirement**: accuracy on `X_test` should be 0.99 otherwise zero points\n",
    "    - Accuracy vs Learning Rate plot: 20 points - Incomplete/wrong plots get zero points\n",
    "    - Questions: 10 points (5 points each)\n",
    "\n",
    "\n",
    "- Part-II Regression on `NA_Sales`: [total 50 points]\n",
    "    - Implementation of nn_reg: 40 points - **Test MAE Loss Requirement**: 0.20 for `mae` loss on `X2_test` otherwise zero points \n",
    "    - Questions: 10 points (5 points each)\n",
    "   \n",
    "\n",
    "<b>Note: </b>Follow the instructions of each section carefully. Up to 10 points may be deducted if your submitted notebook is not easy to read and follow or if it has grammatical, spelling or formatting issues.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct implementation and results\n",
    "  * correct answer to the questions\n",
    "  * complete running of all required cells\n",
    "  * readability of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-A4.ipynb```. Submit the completed notebook using the ```Assignment-4``` link on Blackboard.\n",
    "  \n",
    "<font color=red><b>Due Date: Thursday April 28th, 11:59PM.</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
