{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 478 Machine Learning\n",
    "\n",
    "\n",
    "## Getting Started with Tensorflow, Keras, and Tensorboard\n",
    "\n",
    "### Instructor: Fereydoon Vafaei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jacob Enoch YU11019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you get started with Tensorflow/Keras API. **READ ALL SECTIONS VERY CAREFULLY!**\n",
    "\n",
    "**Note**: You should install Tensorflow 2 before starting this notebook.<br> If you have not installed Tensorflow 2 or have installed previous versions of Tensorflow, you need to [install Tensorflow 2](https://www.tensorflow.org/install) before proceeding. Alternatively, you can install Tensorflow 2 using [conda environment](https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/). CPU-only TensorFlow is sufficient for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO.\n",
    "\n",
    "<b>Course Policy Reminder:</b>\n",
    "Debugging and error resolution are always students' responsbility. This policy will be enforced in email communications and the office hours. Keep in mind that all assignments are individual graded tasks. Any collaboration with other students is strictly prohibited and is considered as cheating. Students should NOT share any answer, solution, or code with other students. Violations of these policies would be penalized according to UMBC academic integrity policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Installation Verification](#Installation-Verification)\n",
    "* [A Simple Regression NN](#A-One-Layer-One-Neuron-Regression-Neural-Network-using-Tensorflow/Keras)\n",
    "* [A Multi-layer NN on MNIST Dataset](#A-Multi-Layer-NN-for-Multi-Class-Classification-on-MNIST-Dataset)\n",
    "* [Eager Execution in Tensorflow-2](#Eager-Execution-in-Tensorflow-2)\n",
    "* [Creating the model using the Sequential API](#Creating-the-model-using-the-Sequential-API)\n",
    "* [Fashion MNIST Dataset](#Fashion-MNIST-Dataset)\n",
    "* [California House Pricing](#California-House-Pricing)\n",
    "* [Saving and Restoring the Models](#Saving-and-Restoring-the-Models)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Tensorboard](#Tensorboard)\n",
    "* [Exercise-1](#Exercise-1)\n",
    "* [Exercise-2](#Exercise-2)\n",
    "* [References](#References)\n",
    "* [Grading and Submission](#Grading-and-Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is one of the most popular ML/DL frameworks. Watch this video first:\n",
    "\n",
    "https://www.youtube.com/watch?v=744f60NyAgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your installation using the following cells.\n",
    "\n",
    "**Note**: It is recommended that you install (or upgrade to) the latest stable version of tensorflow 2. While the minimum requirement for tf version for this notebook is 2.0.0 (which is needed to run the textbook and slides codes), it is your responsibility to update tf to the latest stable version for the assignments when/if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 22:41:22.017231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-18 22:41:22.017269: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your tf/keras version should be 2.x.x (latest stable version is recommended)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check that all important packages can be imported. \n",
    "# Note: If you use a separate conda environment for tf, you may need to reinstall some of these libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A One-Layer One-Neuron Regression Neural Network using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first example is a regression NN with only one layer and one neuron to recognize the pattern of a sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 22:41:32.994342: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-18 22:41:32.994368: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-18 22:41:32.994387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jacob): /proc/driver/nvidia/version does not exist\n",
      "2022-04-18 22:41:32.995533: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.9931\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7118\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4876\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3083\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1644\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0484\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9545\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8779\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8150\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7630\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7196\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6829\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6517\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6248\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6014\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5807\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5621\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5454\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5301\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5160\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5029\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4906\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4790\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4679\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4573\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4472\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4374\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4279\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4188\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4099\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4012\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3928\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3846\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3766\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3688\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3611\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3537\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3463\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3392\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3322\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3254\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3187\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3121\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3057\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2994\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2932\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2872\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2813\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2755\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2699\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2643\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2589\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2536\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2484\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2433\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2383\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2334\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2286\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2239\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2193\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2148\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2104\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2060\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2018\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1977\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1936\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1896\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1857\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1819\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1782\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1745\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1709\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1674\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1640\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1606\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1573\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1541\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1509\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1478\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1448\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1418\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1389\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1360\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1333\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1305\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1278\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1252\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1226\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1201\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1176\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1152\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1129\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1105\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1083\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1061\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1039\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1017\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0997\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0976\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0956\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0936\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0917\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0898\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0880\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0862\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0844\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0827\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0810\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0793\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0777\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0761\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0745\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0730\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0715\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0700\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0686\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0672\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0658\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0644\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0631\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0618\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0606\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0593\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0581\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0569\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0557\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0546\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0535\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0524\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0513\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0502\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0492\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0482\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0472\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0462\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0453\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0444\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0434\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0426\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0417\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0408\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0400\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0392\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0384\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0376\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0368\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0360\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0353\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0346\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0339\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0332\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0325\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0318\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0312\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0305\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0299\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0293\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0287\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0281\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0275\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0270\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0264\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0259\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0253\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0248\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0243\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0238\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0233\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0228\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0224\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0219\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0215\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0210\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0206\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0202\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0197\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0193\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0189\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0186\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0182\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0174\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0171\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0167\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0164\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0160\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0157\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0154\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0151\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0148\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0145\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0142\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0139\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0136\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0133\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0130\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0128\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0125\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0122\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0120\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0118\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0113\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0110\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0108\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0106\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0104\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0102\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0100\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0097\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0095\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0094\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0090\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0088\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0086\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0084\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0083\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0081\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0078\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0076\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0074\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0073\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0070\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0067\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0066\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0064\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0063\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0059\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0058\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0057\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0056\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0053\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0052\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0051\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0049\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0047\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0046\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0045\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0044\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0043\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0043\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0042\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0041\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0040\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0039\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0038\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0037\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0036\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0035\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0035\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0034\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0033\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0032\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0032\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0031\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0030\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0030\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0029\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0029\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0028\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0027\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0026\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0026\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0025\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0025\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0024\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0023\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0023\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0022\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0021\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0021\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0020\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0019\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0019\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0018\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0016\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0016\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0015\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0014\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0014\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0014\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0012\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0011\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0011\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0011\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0010\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9418e-04\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.7376e-04\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.5376e-04\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.3417e-04\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.1498e-04\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.9618e-04\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.7778e-04\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5974e-04\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.4209e-04\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2479e-04\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.0785e-04\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.9126e-04\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7500e-04\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5908e-04\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.4349e-04\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.2822e-04\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1326e-04\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9861e-04\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.8426e-04\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7020e-04\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5644e-04\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.4296e-04\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2975e-04\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1681e-04\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.0414e-04\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9173e-04\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7958e-04\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6767e-04\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.5601e-04\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4459e-04\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3341e-04\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.2245e-04\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1172e-04\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.0121e-04\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.9091e-04\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8083e-04\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7095e-04\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.6128e-04\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.5180e-04\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4252e-04\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3343e-04\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2453e-04\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1581e-04\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.0727e-04\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9891e-04\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9071e-04\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.8269e-04\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.7483e-04\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6713e-04\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5959e-04\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5220e-04\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4496e-04\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3788e-04\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.3094e-04\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.2414e-04\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1748e-04\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1096e-04\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0458e-04\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9832e-04\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9219e-04\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8619e-04\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8031e-04\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7455e-04\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6892e-04\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6339e-04\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5798e-04\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5268e-04\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4749e-04\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4241e-04\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3743e-04\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3255e-04\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.2778e-04\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2310e-04\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1851e-04\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.1403e-04\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0963e-04\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0532e-04\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0111e-04\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9697e-04\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9293e-04\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8897e-04\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8508e-04\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8128e-04\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7756e-04\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7391e-04\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7034e-04\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6684e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6342e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6006e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5677e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5355e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5039e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4731e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4428e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4132e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3841e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3557e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3279e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3006e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2739e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2477e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2221e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1970e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1724e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1483e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1247e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1016e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0790e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0568e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0351e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0139e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9305e-05\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.7265e-05\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.5266e-05\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3310e-05\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1393e-05\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.9516e-05\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.7678e-05\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.5878e-05\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.4113e-05\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2386e-05\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0693e-05\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.9036e-05\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7414e-05\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.5822e-05\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.4264e-05\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2740e-05\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1245e-05\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9781e-05\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8349e-05\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6943e-05\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.5569e-05\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.4221e-05\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.2902e-05\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1611e-05\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.0345e-05\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.9105e-05\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7892e-05\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.6701e-05\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5536e-05\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4396e-05\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.3279e-05\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2184e-05\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.1112e-05\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.0063e-05\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.9034e-05\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.8027e-05\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7041e-05\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.6074e-05\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.5128e-05\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.4202e-05\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3293e-05\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.2404e-05\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1533e-05\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0680e-05\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.9844e-05\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9025e-05\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8224e-05\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7439e-05\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.6669e-05\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5917e-05\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.5179e-05\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.4457e-05\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.3748e-05\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.3056e-05\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2376e-05\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.1712e-05\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1060e-05\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0422e-05\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.9798e-05\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9186e-05\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8586e-05\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7999e-05\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7423e-05\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6860e-05\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.6308e-05\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5767e-05\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5238e-05\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4720e-05\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4211e-05\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3714e-05\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3227e-05\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.2750e-05\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2283e-05\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1826e-05\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1377e-05\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0938e-05\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0507e-05\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0086e-05\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.9674e-05\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9270e-05\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8874e-05\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8486e-05\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8107e-05\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.7735e-05\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7371e-05\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7014e-05\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6665e-05\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6322e-05\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5987e-05\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5659e-05\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5338e-05\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5022e-05\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4714e-05\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4412e-05\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4116e-05\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3825e-05\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3541e-05\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3263e-05\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2991e-05\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2724e-05\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2463e-05\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2207e-05\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1956e-05\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1711e-05\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1470e-05\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1234e-05\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1004e-05\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0777e-05\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0556e-05\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0339e-05\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0127e-05\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.9194e-06\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7155e-06\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.5155e-06\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3201e-06\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1290e-06\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.9412e-06\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7580e-06\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.5779e-06\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.4017e-06\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.2294e-06\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.0603e-06\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.8949e-06\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.7328e-06\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5735e-06\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4184e-06\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.2659e-06\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.1164e-06\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9705e-06\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8273e-06\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.6867e-06\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5495e-06\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4151e-06\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2833e-06\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1540e-06\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0276e-06\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9041e-06\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7827e-06\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.6637e-06\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5473e-06\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.4335e-06\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3219e-06\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2126e-06\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.1058e-06\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0009e-06\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.8981e-06\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.7973e-06\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.6988e-06\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.6025e-06\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5079e-06\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4153e-06\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.3245e-06\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2359e-06\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.1489e-06\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0636e-06\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9804e-06\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.8983e-06\n",
      "Epoch 588/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8181e-06\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7398e-06\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6632e-06\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5880e-06\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.5141e-06\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4421e-06\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3712e-06\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3021e-06\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2342e-06\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1677e-06\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1026e-06\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.0391e-06\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9767e-06\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9156e-06\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.8555e-06\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7969e-06\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7394e-06\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6830e-06\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6280e-06\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5739e-06\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5209e-06\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4694e-06\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4186e-06\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3686e-06\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3200e-06\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2724e-06\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2255e-06\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1801e-06\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1352e-06\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0913e-06\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0483e-06\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0063e-06\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9653e-06\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9246e-06\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8852e-06\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8465e-06\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8086e-06\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7715e-06\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7351e-06\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6994e-06\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6644e-06\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6302e-06\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5969e-06\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5641e-06\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5320e-06\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5005e-06\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4696e-06\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4394e-06\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4098e-06\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3809e-06\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3526e-06\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3248e-06\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2975e-06\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2709e-06\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2448e-06\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2192e-06\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1942e-06\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1698e-06\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1458e-06\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1221e-06\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0992e-06\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0765e-06\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0544e-06\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0327e-06\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0114e-06\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.9067e-07\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7024e-07\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5047e-07\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3092e-07\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.1181e-07\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.9301e-07\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.7476e-07\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5676e-07\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.3921e-07\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.2193e-07\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0503e-07\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.8844e-07\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7231e-07\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5628e-07\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.4072e-07\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2557e-07\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1063e-07\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.9618e-07\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8191e-07\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6786e-07\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.5412e-07\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.4071e-07\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.2751e-07\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1464e-07\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0195e-07\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.8955e-07\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7747e-07\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6574e-07\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5408e-07\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4267e-07\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3150e-07\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2063e-07\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.0986e-07\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.9941e-07\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8910e-07\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7907e-07\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6929e-07\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.5968e-07\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.5012e-07\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4085e-07\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.3187e-07\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2296e-07\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1434e-07\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0579e-07\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9742e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8921e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.8126e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7337e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6578e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5822e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5091e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4370e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3657e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2966e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2293e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1635e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0982e-07\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.0345e-07\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9722e-07\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9115e-07\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8517e-07\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7926e-07\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7354e-07\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6797e-07\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6240e-07\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5700e-07\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.5177e-07\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4657e-07\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4156e-07\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3654e-07\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3167e-07\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2698e-07\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2225e-07\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1775e-07\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1330e-07\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0890e-07\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0461e-07\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0042e-07\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9620e-07\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9223e-07\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8822e-07\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8443e-07\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8060e-07\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7695e-07\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7332e-07\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6975e-07\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6625e-07\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6287e-07\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5952e-07\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5617e-07\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5298e-07\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4982e-07\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4675e-07\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4373e-07\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4077e-07\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3786e-07\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3502e-07\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3226e-07\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2957e-07\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2691e-07\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2432e-07\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2175e-07\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1926e-07\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1678e-07\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1437e-07\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1206e-07\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0972e-07\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0752e-07\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0532e-07\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0313e-07\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0103e-07\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.8958e-08\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.6924e-08\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.4930e-08\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.2941e-08\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1075e-08\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.9201e-08\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.7351e-08\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5563e-08\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.3779e-08\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.2064e-08\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0357e-08\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.8731e-08\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7125e-08\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.5539e-08\n",
      "Epoch 778/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3977e-08\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2505e-08\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0981e-08\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9544e-08\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8117e-08\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6704e-08\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5326e-08\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3989e-08\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2680e-08\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.1406e-08\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.0132e-08\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8929e-08\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7721e-08\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6514e-08\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5348e-08\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.4214e-08\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3129e-08\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.2021e-08\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0970e-08\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.9917e-08\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.8902e-08\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7877e-08\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6914e-08\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5935e-08\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.5006e-08\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.4078e-08\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3173e-08\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2277e-08\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1404e-08\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0532e-08\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9695e-08\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8886e-08\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.8089e-08\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7324e-08\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6550e-08\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5813e-08\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5065e-08\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4348e-08\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3642e-08\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2962e-08\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.2271e-08\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1605e-08\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0972e-08\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0345e-08\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9725e-08\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9112e-08\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8510e-08\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7914e-08\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7369e-08\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.6780e-08\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6252e-08\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5728e-08\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5172e-08\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4658e-08\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4152e-08\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3648e-08\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3182e-08\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2700e-08\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2212e-08\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1762e-08\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1312e-08\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.0890e-08\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0482e-08\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0055e-08\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9636e-08\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9251e-08\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8859e-08\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8465e-08\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.8087e-08\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7721e-08\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7366e-08\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7011e-08\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6664e-08\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6312e-08\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5975e-08\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5663e-08\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5331e-08\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5008e-08\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4707e-08\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4410e-08\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4109e-08\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3821e-08\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3529e-08\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3250e-08\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2993e-08\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2734e-08\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2464e-08\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2221e-08\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1960e-08\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1714e-08\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1478e-08\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1253e-08\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1018e-08\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0798e-08\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0568e-08\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0349e-08\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0140e-08\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.9432e-09\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.7303e-09\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.5209e-09\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.3391e-09\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1315e-09\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.9488e-09\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7645e-09\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.5875e-09\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.4135e-09\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.2538e-09\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0809e-09\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.9116e-09\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7565e-09\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.5966e-09\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.4385e-09\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2885e-09\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.1453e-09\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0058e-09\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8540e-09\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.7151e-09\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5824e-09\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.4514e-09\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3192e-09\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1955e-09\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.0655e-09\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.9402e-09\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8130e-09\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6920e-09\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.5764e-09\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.4681e-09\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3537e-09\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2376e-09\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.1228e-09\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0265e-09\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.9159e-09\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.8211e-09\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.7240e-09\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.6273e-09\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5212e-09\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4406e-09\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.3511e-09\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2613e-09\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1765e-09\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.0843e-09\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9962e-09\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9264e-09\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8421e-09\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7638e-09\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6906e-09\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6108e-09\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.5425e-09\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4645e-09\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.3957e-09\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3329e-09\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2576e-09\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1941e-09\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1335e-09\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0679e-09\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.0065e-09\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9455e-09\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8889e-09\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8325e-09\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7736e-09\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7149e-09\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6606e-09\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6065e-09\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.5500e-09\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4970e-09\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4479e-09\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3943e-09\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3433e-09\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3020e-09\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2503e-09\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2034e-09\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1610e-09\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1124e-09\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0671e-09\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0208e-09\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.9815e-09\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9436e-09\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9033e-09\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8639e-09\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8279e-09\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7859e-09\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7503e-09\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7128e-09\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6759e-09\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6438e-09\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6101e-09\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5790e-09\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5479e-09\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5138e-09\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4833e-09\n",
      "Epoch 968/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4513e-09\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4263e-09\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3950e-09\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3662e-09\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3358e-09\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3077e-09\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2849e-09\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2624e-09\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2351e-09\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2082e-09\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1863e-09\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1646e-09\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1363e-09\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1149e-09\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0884e-09\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0696e-09\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0522e-09\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0281e-09\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0088e-09\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.9195e-10\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.7406e-10\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5530e-10\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3042e-10\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.1314e-10\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.9709e-10\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.7493e-10\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5717e-10\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.4240e-10\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.2474e-10\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1024e-10\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.9488e-10\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8065e-10\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.6370e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82456f7d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple linear regression NN with one layer\n",
    "\n",
    "# build a one-layer one-neuron NN\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # 'mse'\n",
    "\n",
    "# data: y = 2x - 1\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float) \n",
    "\n",
    "# train NN\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred when x=10.0 [[18.999916]]\n",
      "Parameters: [array([[1.999988]], dtype=float32), array([-0.9999638], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# using NN, predict y when x=10.0\n",
    "print(\"y_pred when x=10.0\", model.predict([10.0]))\n",
    "\n",
    "print(\"Parameters: {}\".format(layer_1.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Layer NN for Multi-Class Classification on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.74901961, 0.54117647, 0.09411765, 0.09411765,\n",
       "        0.42352941, 0.54117647, 0.13333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2745098 , 0.98823529, 0.98823529, 0.99215686, 0.98823529,\n",
       "        0.98823529, 0.98823529, 0.98823529, 0.63529412, 0.34509804,\n",
       "        0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.94117647, 0.98823529, 0.99215686, 0.94117647,\n",
       "        0.71764706, 0.71764706, 0.96470588, 0.99215686, 0.98823529,\n",
       "        0.79215686, 0.55686275, 0.02745098, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14509804, 0.38431373, 0.82745098, 0.80784314,\n",
       "        0.        , 0.        , 0.16470588, 0.42745098, 0.69411765,\n",
       "        0.98823529, 0.98823529, 0.82745098, 0.16862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.21176471, 0.70196078, 0.98823529, 0.8627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16862745, 0.94509804, 1.        , 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.90196078, 0.99215686, 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.96470588, 0.96862745, 0.2627451 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5254902 , 0.98823529, 0.36862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45490196, 0.97254902, 0.78431373, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.38039216,\n",
       "        0.87058824, 0.75294118, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14901961, 0.38823529, 0.81568627, 0.89019608,\n",
       "        0.68235294, 0.06666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.81176471, 0.98823529, 0.92941176, 0.34509804,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31372549, 0.79215686, 0.99215686, 0.95686275,\n",
       "        0.81176471, 0.31372549, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313725, 0.37647059, 0.98823529,\n",
       "        0.98823529, 0.95686275, 0.28627451, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.78039216, 0.97647059, 0.99215686, 0.50196078, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4627451 , 0.97254902, 0.99215686, 0.44313725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.45098039, 0.99215686, 0.94117647,\n",
       "        0.19607843, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.98823529,\n",
       "        0.27058824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.90588235,\n",
       "        0.14509804, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-layer NN for multi-class classification\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer - Use Flatten to make it a 1D vector\n",
    "  tf.keras.layers.Dense(128, activation='relu'), # hidden layer with 128 neurons\n",
    "  tf.keras.layers.Dropout(0.2), # dropout is a regularization technique\n",
    "  tf.keras.layers.Dense(10, activation='softmax')]) # output layer has 10 neurons and softmax activation function\n",
    "\n",
    "# compile model for multi-class classification\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # loss='SparseCategoricalCrossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notes**:\n",
    "\n",
    "> These classifiers process vectors, which are 1D, whereas the current input is a rank-3 tensor (60000, 28, 28). To bridge the gap, we flatten the 3D inputs to 1D with a `Flatten` layer before adding the `Dense` layers.\n",
    "\n",
    "> Use `loss='sparse_categorical_crossentropy'` loss function when there are two or more label classes. `tf` expects labels to be provided as integers. If you want to provide labels using `one-hot` representation, use `CategoricalCrossentropy` loss.\n",
    "\n",
    "> Read more about the [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) and [`CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in their tf documentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2958 - accuracy: 0.9140\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1420 - accuracy: 0.9579\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1087 - accuracy: 0.9669\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0879 - accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0765 - accuracy: 0.9763\n",
      "313/313 - 0s - loss: 0.0807 - accuracy: 0.9752 - 415ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08071020990610123, 0.9751999974250793]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# test NN\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution in Tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2 has this new capability of [\"Eager Execution\"](https://www.tensorflow.org/guide/eager) which makes it more convenient to work with tensors and graph computations. See examples below and compare it with tensorflow 1 which uses Session() and Run() to execute these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.Variable(4, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'x:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'y:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())\n",
    "print(y.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s review the steps in building a neural network! Here is a classification MLP with two hidden\n",
    "layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a NN for MNIST\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # the input layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # the first hidden layer with 300 neurons\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # the 2nd hidden layer with 100 neurons\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # the output layer: it's a 10-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through this code line by line:\n",
    "- The first line creates a Sequential model. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the Sequential API.\n",
    "\n",
    "- Next, we build the first layer and add it to the model. It is a `Flatten` layer whose role is to convert each input image into a 1D array: if it receives input data X , it computes `X.reshape(-1, 1)`. This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape` , which doesn’t include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `input_shape=[28,28]`\n",
    "\n",
    "- Next we add a `Dense` hidden layer with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    "\n",
    "$$h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{X}) = \\phi (\\mathbf{X} \\mathbf{W} + \\mathbf{b})$$\n",
    "\n",
    "- Then we add a second `Dense` hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "\n",
    "- Finally, we add a `Dense` output layer with 10 neurons (one per class), using the\n",
    "softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Specifying `activation=\"relu\"` is equivalent to specifying `activation=keras.activations.relu`. Other activation functions are available in the keras.activations package. See https://keras.io/activations/ for the full list.\n",
    "\n",
    "> Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [another example of image classification](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-class classification NN\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')]) # the output layer has 10 neurons and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.5074 - accuracy: 0.8212 - val_loss: 0.4298 - val_accuracy: 0.8430\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3823 - accuracy: 0.8616 - val_loss: 0.3595 - val_accuracy: 0.8722\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3420 - accuracy: 0.8750 - val_loss: 0.3525 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3169 - accuracy: 0.8837 - val_loss: 0.3510 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2981 - accuracy: 0.8914 - val_loss: 0.3344 - val_accuracy: 0.8805\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2843 - accuracy: 0.8954 - val_loss: 0.3254 - val_accuracy: 0.8822\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2714 - accuracy: 0.8983 - val_loss: 0.3455 - val_accuracy: 0.8747\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2600 - accuracy: 0.9032 - val_loss: 0.3305 - val_accuracy: 0.8778\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2466 - accuracy: 0.9086 - val_loss: 0.3434 - val_accuracy: 0.8795\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2394 - accuracy: 0.9109 - val_loss: 0.3308 - val_accuracy: 0.8828\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `fit()` method returns a History object containing the training parameters `history.params`, the list of epochs it went through `history.epoch`, and most importantly a dictionary `history.history` containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 10, 'steps': 1688}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you use this dictionary to create a pandas `DataFrame` and call its `plot()` method, you get the learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA830lEQVR4nO3deXxU5aH/8c8zS2bLHkgggCwKgoqIIIpWRa2VWhVtL8WlVqnLra16W7tZa1vb2uXWtrebteV6tXXFvddWqld/mlrcCloUFUFkDYtkI5Bkktme3x8zmcxkgQBDThi+79drXnPmOc8588zD8p3nOWfOMdZaRERExDkupxsgIiJysFMYi4iIOExhLCIi4jCFsYiIiMMUxiIiIg5TGIuIiDhst2FsjLnLGLPNGPN2H+uNMebXxpjVxpi3jDHH5r6ZIiIi+as/I+M/ArN3sf7jwPjU42rgjn1vloiIyMFjt2FsrX0RaNxFlTnAPTbpVaDUGDM8Vw0UERHJd7k4ZjwC2JjxujZVJiIiIv3gGcg3M8ZcTXIqm0AgMG3UqFE523cikcDl0vloA0F9PTDUzwND/Tww1M+watWqemvt0N7W5SKMNwGZqToyVdaDtXYBsABg+vTpdunSpTl4+6SamhpmzZqVs/1J39TXA0P9PDDUzwND/QzGmPV9rcvF15Qngc+mzqo+AWi21m7JwX5FREQOCrsdGRtjHgRmAUOMMbXAdwEvgLX298Ai4GxgNdAGzN9fjRUREclHuw1ja+1Fu1lvgS/mrEUiIiIHmYP7aLqIiMggoDAWERFxmMJYRETEYQpjERERhymMRUREHKYwFhERcZjCWERExGEKYxEREYcpjEVERBymMBYREXGYwlhERMRhCmMRERGHKYxFREQcpjAWERFxmMJYRETEYQpjERERhymMRUREHKYwFhERcZjH6QaIiMhBzFpIxMHGIRFLLnc+p8s6y7uXJbqW0+X9LYt3vVdvZYkYeHxw+s0D0g0KYxGRg1E8BrH2jEdH8jna3q28t3UdEAv3Ud5tu2iy3ontrfCqAZvIDlgbd7onenJ5ko9AmcJYRCSvdYZhPJIRZB19l8U6IN7tdTSc/XpPAnJfQ9DtA48fvP7kCNLjz3j4IDgktS75uu7DekaMPCQVdG4w7q7lHmWd5X2UuTwZ5a6u9Vn77F5vN2XpcmeO3iqMReTgkEhAIto1Kosnn33tdVC/OhWCmWEX6SUE+wrG3uruJmBzMSJ0F3SFnyfQFYqdIRgs7xmS3kDv4ZlV3sf+Ol+7fXscWu/X1DBi1qx9/8x5SmEsIj0lEsnw6P6I9VIWj0A8mgyY9PRjLFmWPg7XMwSTZfF+1t2b+t3age31o84EeHUv+qgzlNIBlhGMbh8UFCZHh93LswKve1n3uhn10kHYWcfv2ChOck9hLOI0a5NBFmmFaGvyOdJKyfa34YNEV9B1ht6eBmR6m4zlWLd68Y7sbfb3cbzMqUe3J2Ma0ts1bej2ZkwlervKvAHwFe2+bj/3/d7qdUw88uhewq5bcGaGptsLxuzfPpKDisJYZE/EY6nAbEuFZks6PLOWM0I1u05vj5Zew28qwLJ+tsu4UyFSkHx2FyQDw+3rWvb4ks8FoYw6Bd2286aefRnL3ffbrW7nfl2d9XcTgA4el+vN1tYaJh49y+lmyEFOYSz5K9YBHS0Q2dlHMLb0Eaqp19Fe1sXa+//+Lk8y+AoKU8+p5aJh4A32vi69HGLZ2ys4ZtqMngHo8XUL21TgicgBS2Esg0fndG3HzmSAdrSkllPPWcst0LEj9bqPevFI/9/bG+oZir7iZHD2FZi9bZP52lPQv48dj5Nobe16tLWRaGijbbOblvIObDwMiTg2kUidhJTAxhNgU8+d67LKEthEPLvMJrDxOCRsz3Wd9RPJ33z2WpawEO9qR3pdPI61yfc3BQW4gkFcwQCuYBATCOAKhpJlgQCuUOo5GMQEgsnyzrJAAOP17uVfHhn0EgkSkQhEo9hoFBuLdT2iUchYTj7HsLHM8ox1neXRzG2S67LKY9GufUcz3q9z+0i3dsSikLFPVyjEoX9bNCDdozCWfWNt8mcS/Q7MnV3requXiPXvfQsKk8cNO599hRAc3bWcua6gMFnW20jUG0w+9mDa1MbjycBsa+sK0G2tJFo3ZQdqajmeGbStbT3W2/beR9tlwMZ+t2oPGQNuN8blApcr/Yzbjem2DrcLY7qtc7ugWxkuk/zPrbNvwmESbW3JLxD9bZbXmwzqYCqog13h7QoGkuWBbutSYZ7eJhDMCn1XIIAp6N8Xo71hrU0GTFa4xCAVDjYe7z1YYr2UxWN918kIk16/FPX6pSzjS1TqC1Nym25f2LLK+v6ylV3Wx34z1mXur8paVu63P4UUYzAeD3i9GK8X4/FkPfB6MJ7sda5gADyp8s66Xi94PbhDof3d4jSFsYOyRjrW7n45YZM/mO/8y969fJfLidSVbrpGST32GWmD9h0QbsaGm5PL7Tuw7TugfSe0t2A7dnJEazPND1mIhzHxdiD5n60xgLEZy6SWbbKgIIjxBqAgAL4gpiAIBVXgG4cJhaAgCL5CjC8EvlBquTAdrsZfCP4iKAgl/2F1Bokxu142hkS4vSsQm1tJtNaRaFvXFY5ZI9Ps4Ix3e23D4f79ARuTGvmFko/Usnf48K6yUCgZHMHUc0bdZW+/zbHTp4NxJcOv83O53Vll6dB0uXsvc3UL186+GQDWWmxHRzKYW9uw4bauLzKpskSqzKbCO1mWWk6ti23blr1dW1vyP/v+SoV8ZkAnQz9AaWMTG+67PyP44r2PlDIeRKPJkE0F44DpDIvOL069fInCZTAud/aXKJdJHbt3dW3brX7mftP7yPi7lPy71W1db2V91F+3cQNjDxufCrtU4GWGoDcVmJ6MwPRmBGm6vCswk+UZZe4D93CNwngA2HicyIYNdKx6n45Vq9KPyMaNezRqGHz8qceeCqceDbltTg64gkFMKIg72BWW3sqqHoHaI0xDoaxAdYdCmEAg+R/TXoq2tRE4+ugcfrqBZ4zB+P24/H4oK8vZfq212Gg0/eUoHdRt2SG+q4C3bWHi9Q24duwgnhpRGY8HE/SBx91tpOTpZfSUPFu71yDpXubuLWx6CRqPu+t1t5EdHs+AfYnaH96pqWGIfmfcJ4VxDllridfX075qVXbwfvBB11SkMRQccgi+CRMomj0b4yvI+EZpklN/3ZZxGYyNJ08oirVhIq0Qa4NoCybSAtFWTHRnxslKOzHRFiABJjVATY1UDTY5RRsowvhLIFiKCZRAoBSCpRAowwTKIFSWXA6WJUejnd94jeG1115jxvTpXSPtzFF3IpGcxtrdSL1zKi2j/m63TWRuk1E/Xd7XcgKXP5AdoL2FanDfwlMGjjEmeXy6oGCfQ76mpoajFRLiMIXxXkq0ttKxenWP4I03NaXruIcMwT9hPGXz5uGbMCH5OOxQXIFAMry2r4eWbdDWAK310FafWm5ILremXrc1JI+n9sa4IFAOFUOSFxgIjoZQ53JFajnjOViRPBt3H8TXrME3duw+7UNERLoojHfDxmJE1q+nY9WqrOCNbuw6tcYEAvjGj6fwjNPxd4buhAl4ysu7dpSIw4dvw7K7Yf1LsOGVZMh25/GngrQ8GaAVh6WCtDxZng7V1LK/dFD9ZlNERPacwjjFWkts27asY7rtq94n8sEH2EjqJzIuFwVjxuA/8khKLjg/HbzekSN7Tm/Go7BxSTJ4178EG15NnjEMUDoaxp8Fo2ZA8QgIVXSNZAtCurKPiMhB5qAM43hLS4+Tqdrff59Ec3O6jqeyEt+ECYRmzsQ3YTz+CRMoOPRQXL4+pnij7bBpKax/GdYthtolyWO8AEMmwFGfhNEfgdEzoWTkAHxKERE5UOR1GNtolI61a3sEb3Tz5nQdVyiEb/x4is86KzW9PB7f+PF4dndSSEcLbHwtGb7rX04GcTwCGKg6CqZeCqNPTD4KK/fvBxURkQNaXoSxtRZXYyM7a2qyg3ftWohGk5U8HnxjxxA45hhKP/3p9HFd74jq/v1cINyUnGpe/1IyfDcvS15P2Lih+hg4/t9h9ElwyAnJG1KLiIj0U16EcdMDDzD0B7dSm3rtGT4c34TxFJ56Sjp0C8aOTf4Mor9a6rqCd/3LyZOvsMlrAo+YDh/5cnLUO2pG8ipPIiIieykvwjg0cyY7LryQyed8At/48bhLSvZ8J82bUsG7OPlcvypZ7gkkA/e0m5LhO2Ja8hZuIiIiOZIXYewbN47wrFMJTp/evw2shaa1qZOtUmc7b1+f2llxcqr5mEuS087Dp/T7gv8iIiJ7Iy/CeLeshbqV2dPOO1MncQXKkyPeE65JPlcdpdvRiYjIgMrPMO68wMb6l7sCuPMCG4XDYMxJqTOdP5L82ZEumiEiIg7KjzCORynasRIWL0sG74ZXoSP1m+HOC2yMPjEZwmVjdVENEREZVPIjjJfexbQ3vp5cHjIBjrogebx39Im6wIaIiAx6+RHGh5/NO+vrOfLsq3SBDREROeDkx8HS0lHUVZ6kIBYRkQNSv8LYGDPbGLPSGLPaGHNjL+sPMca8YIz5lzHmLWPM2blvqoiISH7abRgbY9zA7cDHgSOAi4wxR3SrdjPwsLV2KnAh8LtcN1RERCRf9WdkPANYba1dY62NAAuBOd3qWKA4tVwCbEZERET6xVhrd13BmH8DZltrr0y9vhQ43lp7bUad4cD/AWVACPiotfb1XvZ1NXA1QFVV1bSFCxfm6nPQ0tJCYWFhzvYnfVNfDwz188BQPw8M9TOcdtppr1tre71UZK7Opr4I+KO19ufGmJnAvcaYo6y1icxK1toFwAKA6dOn21mzZuXo7aGmpoZc7k/6pr4eGOrngaF+Hhjq513rzzT1JmBUxuuRqbJMVwAPA1hrXwH8wJBcNFBERCTf9SeMlwDjjTFjjTEFJE/QerJbnQ3AGQDGmEkkw7gulw0VERHJV7sNY2ttDLgWeAZYQfKs6XeMMd83xpyXqvYV4CpjzJvAg8DldncHo0VERATo5zFja+0iYFG3su9kLL8LnJTbpomIiBwc8uMKXCIiIgcwhbGIiIjDFMYiIiIOUxiLiIg4TGEsIiLiMIWxiIiIwxTGIiIiDlMYi4iIOExhLCIi4jCFsYiIiMMUxiIiIg5TGIuIiDhMYSwiIuIwhbGIiIjDFMYiIiIOUxiLiIg4TGEsIiLiMIWxiIiIwxTGIiIiDlMYi4iIOExhLCIi4jCFsYiIiMMUxiIiIg5TGIuIiDhMYSwiIuIwhbGIiIjDFMYiIiIOUxiLiIg4TGEsIiLiMIWxiIiIwxTGIiIiDlMYi4iIOExhLCIi4jCFsYiIiMMUxiIiIg5TGIuIiDhMYSwiIuIwhbGIiIjDFMYiIiIOUxiLiIg4TGEsIiLiMIWxiIiIwxTGIiIiDlMYi4iIOExhLCIi4rB+hbExZrYxZqUxZrUx5sY+6nzaGPOuMeYdY8wDuW2miIhI/vLsroIxxg3cDpwJ1AJLjDFPWmvfzagzHvgmcJK1tskYU7m/GiwiIpJv+jMyngGsttausdZGgIXAnG51rgJut9Y2AVhrt+W2mSIiIvmrP2E8AtiY8bo2VZZpAjDBGPOSMeZVY8zsXDVQREQk3+12mnoP9jMemAWMBF40xky21m7PrGSMuRq4GqCqqoqampocvT20tLTkdH/SN/X1wFA/Dwz188BQP+9af8J4EzAq4/XIVFmmWuA1a20UWGuMWUUynJdkVrLWLgAWAEyfPt3OmjVrL5vdU01NDbncn/RNfT0w1M8DQ/08MNTPu9afaeolwHhjzFhjTAFwIfBktzp/JjkqxhgzhOS09ZrcNVNERCR/7TaMrbUx4FrgGWAF8LC19h1jzPeNMeelqj0DNBhj3gVeAL5mrW3YX40WERHJJ/06ZmytXQQs6lb2nYxlC9yQeoiIiMge0BW4REREHKYwFhERcZjCWERExGEKYxEREYcpjEVERBymMBYREXGYwlhERMRhCmMRERGHKYxFREQcpjAWERFxmMJYRETEYQpjERERhymMRUREHKYwFhERcZjCWERExGEKYxEREYcpjEVERBymMBYREXFY3oRxLGGdboKIiMheyYswrlm5jW/+I8yyjdudboqIiMgey4swLg0WkLAw9/cvc/dLa7FWo2QRETlw5EUYHzOqlO+dGODUCZV87y/vcs19b9AcjjrdLBERkX7JizAGKCww/Pdnp/Gtsyfx3IoPOfc3i3l7U7PTzRIREdmtvAljAGMMV50yjof+fSaxeIJP/u5l7n1lnaatRURkUMurMO40bXQZT11/MicdVsG3//cdrn3wX+xs17S1iIgMTnkZxgBloQL+57Lj+MbsiTz99lbO/c1i3tmsaWsRERl88jaMAVwuwzWzDmXh1ScQjsa54Hcvc/9r6zVtLSIig0peh3Gn48aUs+j6kzlhXAXfeuJtvvTQMlo7Yk43S0REBDhIwhigotDHHy8/jq9+bAJ/eXMz5/52Me9t3eF0s0RERA6eMIbktPW1p4/n/itPYGd7jDm/fYmHlmzQtLWIiDjqoArjTjMPrWDR9SczfUwZ33hsOV95+E3aIpq2FhERZxyUYQwwtMjHPZ87ni99dDxPLNvEeb99iVUf7nS6WSIichA6aMMYwO0yfOmjE7jviuPZ3hZhzm9f4tHXa51uloiIHGQO6jDudNJhQ1h0/clMGVXCVx95k6898ibhSNzpZomIyEFCYZxSWeznviuO57rTD+PRN2o5//aXWL2txelmiYjIQUBhnMHjdvGVjx3On+bPoK6lg/N+u5g//2uT080SEZE8pzDuxSkThrLo+pM5qrqELz20jG8+/hbtUU1bi4jI/qEw7sOwEj8PXHU818w6lAf/uZELfvcya+o0bS0iIrmnMN4Fj9vFN2ZP5O7Lj2NLc5hzf7OYv7y52elmiYhInsmLMN7fV9A6bWIli64/mcOHFXHdg//i5j8v17S1iIjkTF6E8ZKtS7hty2385YO/EIlH9st7VJcGeOjfZ3L1KeO479UNfOqOl1nf0Lpf3ktERA4ueRHGkUSEjkQHNy2+iTMfPZNfv/FrtrZuzfn7eN0ubjp7End+djq1TWHO+fVi/rZ8S87fR0REDi55EcYfGfERvlX9LRacuYApQ6dw5/I7mf3YbG6ouYElW5fkfBr7o0dU8dT1H2FcZSHX3P8Gtzz5Dh0xTVuLiMje8TjdgFwxxjCzeiYzq2eyqWUTD733EI+9/xjPrn+W8WXjuWjiRXxi7CcIeoM5eb+RZUEe+feZ/ORv73HXS2t5Y0MTt198LKPKc7N/ERE5eOTFyLi7EYUjuGH6DTw39zm+d+L3cOHi+698n48++lFuW3IbG3duzMn7FHhcfOfcI/j9Z6axtr6VT/z6HzzzTu6nx0VEJL/1K4yNMbONMSuNMauNMTfuot6njDHWGDM9d03cewFPgE+O/ySPnPsIf5r9J06qPokHVjzAJx7/BNf+v2t5adNLJGxin99n9lHDeOq6kxldEeLf732dH/z1XSKxfd+viIgcHHY7TW2McQO3A2cCtcASY8yT1tp3u9UrAv4DeG1/NHRfGGM4tupYjq06lg9bP+SRVY/wyKpH+Ptzf2dM8RgunHghcw6dQ2FB4V6/xyEVQR69ZiY/emoF/7N4La+vb+K3F09lZJmmrUVEZNf6MzKeAay21q6x1kaAhcCcXur9APhPoD2H7cu5qlAV1069lmf/7Vl+fPKPKfYV85N//oQzHjmDW1+9lTXb1+z1vn0eN9+bcxS3X3wsq7e18IlfL+b/rfgwh60XEZF81J8wHgFkHmStTZWlGWOOBUZZa5/KYdv2qwJ3AeeMO4f7z76fhZ9YyEdHf5TH33+cOf87h6v+7yqe3/A88cTenSH9iaOH89frPsKI0gBX/GkpP160gmhc09YiItI7s7uf/Rhj/g2Yba29MvX6UuB4a+21qdcu4HngcmvtOmNMDfBVa+3SXvZ1NXA1QFVV1bSFCxfm7IO0tLRQWLj308wAO+M7ebnlZRbvXMz2+HbK3eWcXHQyMwtnEnKH9nh/kbjlwfcivLAxxmGlLq6Z4qMicOCfM5eLvpbdUz8PDPXzwFA/w2mnnfa6tbbXc6r6E8YzgVustWelXn8TwFr749TrEuADoPMuCsOARuC83gK50/Tp0+3SpX2u3mM1NTXMmjUrJ/uKJWK8sPEFHnzvQZZsXYLP7ePssWdz8aSLmVg+cY/397/LNnHT48sp8Lj4xbxjOO3wypy00ym57Gvpm/p5YKifB4b6GYwxfYZxf4ZpS4DxxpixxpgC4ELgyc6V1tpma+0Qa+0Ya+0Y4FV2E8SDncfl4czRZ3LXWXfx2HmPce6h5/L0uqeZ+5e5fPZvn+XptU8TTUT7vb85x4zgyes+QlWxn/l3L+E/n36PmKatRUQkZbdhbK2NAdcCzwArgIette8YY75vjDlvfzfQaRPKJvDdmd/l2X97lq9O/yp1bXV87cWvcdajZ3HHm3dQH67v134OHVrIn794EhceN4o7aj7g4v9+ja3Ng/pcNxERGSD9ugKXtXYRsKhb2Xf6qDtr35s1+JT4SrjsyMu49IhLWbxpMQ+seIDfLfsdC95awMdGf4yLJ13M0UOOxhjT5z78Xjc/+dTRHD+unJsef5vZv3qR0ydWcvzYcmaMrWBMRXCX24uISH7Km8thDhSXcXHKyFM4ZeQprGtex8KVC/nz6j+zaO0ijqg4gosnXszssbPxuX197uOCqSOZPKKEXzy7ir+vrOPxNzYBUFnkY8bY8nQ4j68sxOVSOIuI5DuF8T4YUzKGG2fcyHVTr+MvH/yFB997kJtfupmfL/05n5rwKeYdPo9hoWG9bntYZRG/u2Qa1lo+qGvhtbWN/HNtI6+taeSvbyXvBFUW9HLcmPJUQFcwaXgRHveBfza2iIhkUxjnQMgb4sKJFzLv8Hm8tvU1HljxAHe9fRd3vX0Xp486nYsnXcz0qum9TkEbYzissojDKou45PjRWGvZ2BjmtbUN/HNtI/9c18j/vZu8cEihz8P0MWXp0fPkEaUUeBTOIiIHOoVxDhljOGH4CZww/ITknaNWPsTj7z/Ocxue47DSw7ho4kWcM+6cXd45yhjDIRVBDqkIMnf6KAC2Nrd3hfPaRn66ciUAfq+LqaPKOH5ccvQ8dVQZgQL3gHxWERHJHYXxfjKicAQ3TLuBL0z5An9b+zceeO8BfvDqD/jl67/k/PHnc+HhF3JI8SH92tewEj9zjhnBnGOSFz5raOlgybqmdED/6v+9j7XgdRuOHlmaOuZczrTRZRT5vfvzY4qISA4ojPczv8fPBeMv4PzDzmdZ3TIeWPEAD654kPvevY8Zw2cwPDQcv9tPwBsg4AkQ9AQJeJLLfo8/vZz18AY4fVI5Zx1ZhTGG5nCUN9Y38draRl5b28CCF9fwu5oPcBk4srokPa193JhyykIFTneJiIh0ozAeIMYYplZOZWrlVLa1beORVY/w3PrnWNu8lvZYO+FYeI8uJALgNu6skPZ7/ITGBDh1nJ+OqIedYRdNLfDgasu9K72QKGBoqIhxQ8o4vLKCI4cNYVhxcXr7oCeY/lLgd/txuzTlLSIyEBTGDqgMVvLFY77IF4/5YlZ5LBEjHAsTjoXTAR2OhWmLtfVanlmWWSccCxO2YaKedtyFYYp9YdpiYSwJdgDLwrBsPbB+1+0scBWkwzkd+G4/O5t3ct//3YcLFy7jwhiD27gxxqTLOh/GGFzGlVyPyVrnMq7ey/rYj9u4+96GjDZ0W+cyLsp95QwJDqEyUEmJr0S/5xaRQUVhPIh4XB6KCoooKijK+b6ttUQSEcLRMC2RNpZvruONjR/y5uY63vuwnrZoGFwRykIwqsLNsFI3FcXg98azgz/eToIEkXiEhE1kPSy217J4It7nuoRNELdxrLVZ9RMksspyyevyMjQwlKHBoVQGKxkSGEJlsDJZllFeXFCs0BaRAaEwPkgYY/C5ffjcPkr9pYwsrubjqXteJBKWlR/uTJ+t/draRt5o6QBgSKEvfULYjMPLObyqiBdf/PuAXvC9M5Q7AzozvDPLErYrwDvXJWyCWCJGU3sTdeE66trq2BbeRl1bHXXhOj7Y/gGvbn6VndGdPd63wFXA0GBXQHd/rgxUMjQ4VKE9yFlraWhvYEvLFja3bs563tK6hZaWFh589kGGBIZQ4a+gIlBBub+cikBFuqzUV6rDNnsolojR3NHM9o7tNLU3sTK8kmGNwyj1lVLqK8Xv8TvdxEFFYSy4XIZJw4uZNLyYy04cg7WWNfWtXeG8poGnlicvRFLs91DpT/BU3ZuMG1rIuKEhxg0JcUhFEJ9n//xn1TlF7Wbv9z+2ZOwu14djYerb6pNBnQrtzsCua6tj9fbV/Q7tvkbbCu39I5aIUddWx+bWzWxuST62tG5JP29p3UJHvCNrmyJvEcMLh1Mdqqa+vZ4dHTtY27yWhnADkUSkx3u4jIsyX1kynAMV6dBOP2csl/nK8i64EzbBjo4dNHU0pcN1e8f25KN9e7K88zm1fkdkR4/9/PYvv00vBzwBSnwl6XBOP/x9vw568veSwQpj6cEYw6FDCzl0aCEXzUj+/Kq2qY1/rm1k6fomXl9Vywsr63jk9dr0Ni4Do8qDjB0SYtyQrpAeN7SQqmLfoP8HFPAEGFU8ilHFo3ZZry3aRn24vmuU3baN+nB9erS9evtqXtn8Ci3Rlh7b+ty+7JBOBXhWeAeHUuQtGvT9NZA64h29jmo7nz9s+5C4jWdtU+4vZ0ThCCaUTWDWqFkMDw2nurA6/Zx5KCjz1n7WWlqiLTSEG6gP19PQ3kBDuKHrObW8rnkdDe0NPUIeuoK7e2j3CHKHgrvzM3YPz16fUyHbHGkmYXu/01yBq4Ayfxll/jJKfaVUh6op9ZdS5ivLel7+5nLGTBqTDvB0mKcem1s2s71je68h3snr8vYe2L5SSnwl6TZklhUVFOEyg//iSApj6ZeRZUFGlgX55LEjqalpYNasWexoj7K2rpU19S2srWvlg/pW1tS18uqaBtqjXf9wgwXuZEgPLUwFdDKwxw4NUeg7sP4KBr1BDvEestvfiHeG9ra2jJF2uCu8VzWt4qXNL9Eabe2xbWdouyIu7n3mXkLeEIXewuRzQWHW6/RyQUYdbyE+9+D/AtRpZ2Rnj9Fs5nNDe0NWfZdxURWsYnhoOMdWHZsO2OpQNcMLhyd/LriXU6DGmPR5G2NKxuyybmZwZ4Z2fbg+vdwYbmT9jvW7DO5SX2lWSA/xD8kabXeGeKmvFI/L06MN4Vg4a2TaPVC7h2xzRzMxG+v1M3lcnqwQHV86Ph1wZf6yZOBlhqyvlIAn0K+/a+0r25k1etZu68USMXZEdmSFdnNHc/qLQ3NHc/pzrN6+muaOZpo7mnt8IevkNu6sEXhnaKc/Sy9lxQXFA/4l6cD6n1AGlWK/lymjSpkyqjSrPJGwbN3Rzpq6VtbWt/BBXStr6ltZtrGJv761GZtxPlZlkS8Zzt2CemRZ4IC+DveehHZmSG9r6zqevW7rOmKJGJtaNtEabaUl2kJrpLXP/0gzeYyHUEGIkCfUI6gzAzzk6Rnwhd7CdFnQE9yn/5SstTS2N/YI2MzR7c5I9tR/gasgPYXc26i2MljZI5ScsKfB3RptTYd2X6PujTs30hBuoD3e8/aqBkOZv4xyfzlu404HcG/T6tAV9J3hObp4NFOGTskK18z1Zb4yQt6Q41/iPC4P5f5yyv3lUNK/bRI2wc7IzvQx6swvId3Laltqebv+bbZ3bO/z56SG5J/tsNAwHjvvsRx+ur45/zda8o7LZaguDVBdGuAj44dkrWuPxlnf0NYV0qnAXrR8C9vbuv5heN2GQ8qD2SE9tJCxQ0JUhAoc/w8jV4LeIKO9oxldPLrHuszp006dZ8W3RFq6AjraSkukhZZoC23Rtq6yjHWt0Vaa2puo3VmbXheOhfvVxoAn0CPEu4d752NHZEdW6G5t3dojWAq9hemwnVo5NRm0qdfVhdWU+8sPiGnFPWGMobAg+SWntz/rTNZa2mJtWSPs7qNuay1HVByRNULtHrIHyvRsLriMixJfCSW+Eg6hf1c27OznzGPfWVPn7dv7nJrfHxTGMqD8XjeHDyvi8GE9f77V2BrpEdJr6lr5+8o6IvGufxTFfk+vIT12SAi/N79OnOkufVZ8wEdFoGKf9hVLxGiLtdEaae0R4JkhnrmuM/A3tG/I2i5zirDcX051qJrxZeM5deSpWUE7vHA4xQXF+9oNec0Yk/5ys7vglr2X2c8jCkc43RyFsQwe5aECykPlTBtdnlUeT1g2NYX5IBXOnSH98gcNPP6vTel6xkB1SSDr5LGxqcAeVuw/oKe99wePy0NxQfE+h6O1lvZ4O63RVkLeEAFPIEctFDl4KIxl0HO7uu5kddrh2etaO2KsrU8ek+48mWxNXSuPvl5LaySetY/KIh/DS/wMLw1QXeJneEmA6tLk8/BSP0NCPlyu/Jj+HkjGmPQV2kRk7yiM5YAW8nk4akQJR43IPtPDWkvdzg4+qGtlbX0rm7eH2dwcZsv2dt7Z1Myz735IJJZ9PKjA7aKqxJcM6W6hPbzUT3VJgNKgN2+OV4vI4KEwlrxkjKGy2E9lsZ+Zh/Y8tmqtpbE1wpbmdjZvDyefU2G9pTnMknVNfLhjC7FE9qU4A153anTtzwrt4SV+qlPPum2liOwphbEclIwxVBT6qCj09RhVd4onLPUtHV1hnXre0hxm8/Z2/vF+Hdt2dmT9VAugyOfpCuvOafCMsK4uDeT9iWYismcUxiJ9cLsMVcV+qor9TO2jTjSe4MMd7dlhvT3M5lRov72pmYbWnr8DLQt6exyzrs4I7apiXbdX5GCiMBbZB163K311sr60R+Ns7TYNvjkV2rVNYf65tpEd7dkX8jAGQh6oer0mOYIPFVBRWEB5KHO5gIqQj4rCAsqCBbh18pnIAUthLLKf+b1uxgwJMWZIqM86rR2x9PR3Z3C/tXIt/tIi6lsivL+thdfWRmhqi/SYFodkeJcGvFQU+igPFTAkFdblIV/GcgFDUusV3iKDi8JYZBAI+TwcVlnEYZUZNzDwbGbWrGlZ9eIJS1NbhMbWCPUtHTS2RmhoidDQGqGxtSO9vOrDFhpaOtgejvYZ3mXBztF1z5F292WFt8j+pTAWOYC4XYYhhT6GFPqYUNXzKmbdxeIJmtqiydBOhXVyOUJDRpiv3LqTxtYITW19XKs3Fd4VqRF2RWEyrHtbLgsWUBr04tVFVkT6TWEsksc8bhdDi3wMLfIBexjeLR3ZoZ0K7sbWZHg3tDZkXU+8uyK/Jz2q7nwuC3opCxVklZeHvJQGCygNeHWVNDloKYxFJG1vwrsxNW3e0JI8pt3UGqGxNZqeTm9qi7BtZ3t69B2O9n6rO4CSgDcV1N5keGcFd1dZZ5CXBLyaPpe8oDAWkb3mcbuoLPJTWdT/n2KFI/FkaLdFaGqN0pgO8Ajb2yI0tkVpSl2Q5d0tO2hsjdAR6/3uOZ0nrpWlR96p0A4VUJ4V3N50gBf7vbrsqQw6CmMRGVCBAjeBguQtNvsrHIlnhXbXqDsZ3J3rapvaeHtTcpo9805fmVyp49+lweQoPNbWzlN1b1IS8FIa9FISTI64SztfB7yUBgoo8nsU4rLfKIxFZNALFLgZURBgRD8D3FpLWySeFdzbU8fCM6fPG1sjbA1btq6upzkcpS3S9xS6MVDsTwZ0aaD30E4GekE62EsDXooDXl1xTXZLYSwieccYQ8jnIeTzMKq87wuyANTU1DBr1iwAOmJxmsNRmtuiNIejbG+Lsj0cTZVF2J4qaw4nyzc0tCbXhaMkevkJWSe/10VpIDkaL+4+6s4I785ReGe9Ip9G4wcLhbGISIrP46ayyL1Hx8ABEgnLzo4YO9IBHkmHefI5khXuGxrbeKs2Wa892vt0OiSn1DtH3CWpM85LAl7Kgl7KQz7KC5PHxjN/VlYW1FnpByKFsYjIPnK5TDo0R5Xv2bbt0XgyxMMZo/FUeHcfnW9vi7CuoZWm1kiPS6hmKg160yFdFur6fXhvj4qQj0CBptGdNqjCOBqNUltbS3t7+x5vW1JSwooVK/ZDqw5efr+fkSNH4vXqloAi+4vf68bvdVO5hzcHicYT6ZPXGlsiPX5i1tCaLN/Y2Mayjdtpao30uCVoVxtc6Qu37D68dUb6/jCowri2tpaioiLGjBmzxzdw37lzJ0VFu/9dpPSPtZaGhgZqa2sZO3as080RkW68blf6nt39Ya1lR3uMxtSlUxtbo8lLqLYmz0TvfG5sjbCmroWm1gitfZzQ5naZ9G/BM6fIO0O8LNR1VbbOh+zaoArj9vb2vQpiyT1jDBUVFdTV1TndFBHJAWO6ptLH7uKmJZnao/FUePd8ZIb3qg9b0meo93YtdIACNxT941kCBW6CBW4CBR5CGctBrzu9Ll2Wfu1JlaVeez1d+/G682KUPqjCGFAQDyL6sxA5uPm9bqpL+/+b8HjC0hyOpm9akjld/s77a6ioGkY4EqctEqctGiccibF5e5RwNE5bJEZbJE44Eu9zOr0vAa87K6w7wz0rwDPCPTPok9t2hXuowJmgH3Rh7LTCwkJaWlqcboaIyAHH7TLpaenDKrPX1bg3MWvW5H7tJxJLJEM7mgzoto5UWEfj6TAPp8K7LRLvCvOO7KDfuiPaFf6RGOFonGi8/0Ff5POw/Htn7UkX7DWFsYiIDCoFHhcFHhcl5P7k0e5BnxXW3UbtA0lh3AdrLV//+tf529/+hjGGm2++mXnz5rFlyxbmzZvHjh07iMVi3HHHHZx44olcccUVLF26FGMMn/vc5/jyl7/s9EcQEZFu9mfQ74tBG8bf+8s7vLt5R7/rx+Nx3O5d/1buiOpivnvukf3a3+OPP86yZct48803qa+v57jjjuOUU07hgQce4KyzzuJb3/oW8XictrY2li1bxqZNm3j77bcB2L59e7/bLSIiosu09GHx4sVcdNFFuN1uqqqqOPXUU1myZAnHHXccd999N7fccgvLly+nqKiIcePGsWbNGq677jqefvppiouLnW6+iIgcQAbtyLi/I9hOA/U741NOOYUXX3yRp556issvv5wbbriBz372s7z55ps888wz/P73v+fhhx/mrrvu2u9tERGR/KCRcR9OPvlkHnroIeLxOHV1dbz44ovMmDGD9evXU1VVxVVXXcWVV17JG2+8QX19PYlEgk996lPceuutvPHGG043X0REDiCDdmTstAsuuIBXXnmFKVOmYIzhpz/9KcOGDeNPf/oTt912G16vl8LCQu655x42bdrE/PnzSSSSF3z/8Y9/7HDrRUTkQNKvMDbGzAZ+BbiBO621P+m2/gbgSiAG1AGfs9auz3FbB0Tnb4yNMdx2223cdtttWesvu+wyLrvssh7baTQsIiJ7a7fT1MYYN3A78HHgCOAiY8wR3ar9C5hurT0aeBT4aa4bKiIikq/6c8x4BrDaWrvGWhsBFgJzMitYa1+w1ralXr4KjMxtM0VERPJXf6apRwAbM17XAsfvov4VwN96W2GMuRq4GqCqqoqampqs9SUlJezcubMfTeopHo/v9bbSt/b29h5/Ti0tLT3KJPfUzwND/Tww1M+7ltMTuIwxnwGmA6f2tt5auwBYADB9+nQ7a9asrPUrVqzY658n6RaK+4ff72fq1KlZZTU1NXT/s5PcUz8PDPXzwFA/71p/wngTMCrj9chUWRZjzEeBbwGnWms7ctM8ERGR/NefY8ZLgPHGmLHGmALgQuDJzArGmKnAH4DzrLXbct9MERGR/LXbMLbWxoBrgWeAFcDD1tp3jDHfN8acl6p2G1AIPGKMWWaMebKP3YmIiEg3/TpmbK1dBCzqVvadjOWP5rhdeS8Wi+Hx6JorIiKiy2H26vzzz2fatGkceeSRLFiwAICnn36aY489lilTpnDGGWcAybMD58+fz+TJkzn66KN57LHHACgsLEzv69FHH+Xyyy8H4PLLL+fzn/88xx9/PF//+tf55z//ycyZM5k6dSonnngiK1euBJJnhn/1q1/lqKOO4uijj+Y3v/kNzz//POeff356v88++ywXXHDBAPSGiIjsb4N3aPa3G2Hr8n5XD8Rj4N7Nxxk2GT7+k13XAe666y7Ky8sJh8Mcd9xxzJkzh6uuuooXX3yRsWPH0tjYCMAPfvADSkpKWL482c6mpqbd7ru2tpaXX34Zt9vNjh07+Mc//oHH4+G5557jpptu4rHHHmPBggWsW7eOZcuW4fF4aGxspKysjC984QvU1dUxdOhQ7r77bj73uc/tvmNERGTQG7xh7KBf//rXPPHEEwBs3LiRBQsWcMoppzB27FgAysvLAXjuuedYuHBheruysrLd7nvu3Lnp+y43Nzdz2WWX8f7772OMIRqNpvf7+c9/Pj2N3fl+l156Kffddx/z58/nlVde4Z577snRJxYREScN3jDuxwg2UzhHvzOuqanhueee45VXXiEYDDJr1iyOOeYY3nvvvX7vwxiTXm5vb89aFwqF0svf/va3Oe2003jiiSdYt27dbn+DN3/+fM4991z8fj9z587VMWcRkTyhY8bdNDc3U1ZWRjAY5L333uPVV1+lvb2dF198kbVr1wKkp6nPPPNMbr/99vS2ndPUVVVVrFixgkQikR5h9/VeI0aMAOCPf/xjuvzMM8/kD3/4A7FYLOv9qqurqa6u5tZbb2X+/Pm5+9AiIuIohXE3s2fPJhaLMWnSJG688UZOOOEEhg4dyoIFC/jkJz/JlClTmDdvHgA333wzTU1NHHXUUUyZMoUXXngBgJ/85Cecc845nHjiiQwfPrzP9/r617/ON7/5TaZOnZoOXoArr7ySQw45hKOPPpopU6bwwAMPpNddcskljBo1ikmTJu2nHhARkYFmrLWOvPH06dPt0qVLs8pWrFix1yFzsFwO89prr2Xq1KlcccUVA/J+vf2Z6LJ2A0P9PDDUzwND/QzGmNettdN7W6eDjgeQadOmEQqF+PnPf+50U0REJIcUxgeQ119/3ekmiIjIfqBjxiIiIg5TGIuIiDhMYSwiIuIwhbGIiIjDFMYiIiIOUxjvg8y7M3W3bt06jjrqqAFsjYiIHKgUxiIiIg4btL8z/s9//ifvNfb/5gzxeDx9N6S+TCyfyDdmfKPP9TfeeCOjRo3ii1/8IgC33HILHo+HF154gaamJqLRKLfeeitz5szpd7sgebOIa665hqVLl+LxePjFL37BaaedxjvvvMP8+fOJRCIkEgkee+wxqqur+fSnP01tbS3xeJxvf/vb6ctviohIfhq0YeyEefPm8aUvfSkdxg8//DDPPPMM119/PcXFxdTX13PCCSdw3nnnZd2ZaXduv/12jDEsX76c9957j4997GOsWrWK3//+9/zHf/wHl1xyCZFIhHg8zqJFi6iuruapp54CkjeTEBGR/DZow3hXI9je5OLa1FOnTmXbtm1s3ryZuro6ysrKGDZsGF/+8pd58cUXcblcbNq0iQ8//JBhw4b1e7+LFy/muuuuA2DixImMHj2aVatWMXPmTH74wx9SW1vLJz/5ScaPH8/kyZP5yle+wje+8Q3OOeccTj755H36TCIiMvjpmHE3c+fO5dFHH+Whhx5i3rx53H///dTV1fH666+zbNkyqqqqetyjeG9dfPHFPPnkkwQCAc4++2yef/55JkyYwBtvvMHkyZO5+eab+f73v5+T9xIRkcFr0I6MnTJv3jyuuuoq6uvr+fvf/87DDz9MZWUlXq+XF154gfXr1+/xPk8++WTuv/9+Tj/9dFatWsWGDRs4/PDDWbNmDePGjeP6669nw4YNvPXWW0ycOJHy8nI+85nPUFpayp133rkfPqWIiAwmCuNujjzySHbu3MmIESMYPnw4l1xyCeeeey6TJ09m+vTpTJw4cY/3+YUvfIFrrrmGyZMn4/F4+OMf/4jP5+Phhx/m3nvvxev1MmzYMG666SaWLFnC1772NVwuF16vlzvuuGM/fEoRERlMFMa9WL58eXp5yJAhvPLKK73Wa2lp6XMfY8aM4e233wbA7/dz991396hz4403cuONN2aVnXXWWZx11ll702wRETlA6ZixiIiIwzQy3kfLly/n0ksvzSrz+Xy89tprDrVIREQONArjfTR58mSWLVvmdDNEROQApmlqERERhymMRUREHKYwFhERcZjCWERExGEK432wq/sZi4iI9JfCOA/EYjGnmyAiIvtg0P60aeuPfkTHiv7fzzgWj9O4m/sZ+yZNZNhNN/W5Ppf3M25paWHOnDm9bnfPPffws5/9DGMMRx99NPfeey8ffvghn//851mzZg0Ad9xxB9XV1ZxzzjnpK3n97Gc/o6WlhVtuuYVZs2ZxzDHHsHjxYi666CImTJjArbfeSiQSoaKigvvvv5+qqipaWlq47rrrWLp0KcYYvvvd79Lc3Mxbb73FL3/5SwD++7//m3fffZf/+q//2u3nEhGR3Bu0YeyEXN7P2O/388QTT/TY7t133+XWW2/l5ZdfZsiQITQ2NgJw/fXXc+qpp/LEE08Qj8dpaWmhqalpl+8RiURYunQpAE1NTbz66qsYY7jzzjv56U9/ys9//nN+8IMfUFJSkr7EZ1NTE16vlx/+8IfcdttteL1e7r77bv7whz/sa/eJiMheGrRhvKsRbG8G2/2MrbXcdNNNPbZ7/vnnmTt3LkOGDAGgvLwcgOeff5577rkHALfbTUlJyW7DeN68eenl2tpa5s2bx5YtW4hEIowdOxaA5557joULF6brlZWVAXD66afz17/+lUmTJhGNRpk8efIe9paIiOTKoA1jp3Tez3jr1q097mfs9XoZM2ZMv+5nvLfbZfJ4PCQSifTr7tuHQqH08nXXXccNN9zAeeedR01NDbfccssu933llVfyox/9iIkTJzJ//vw9apeIiOSWTuDqZt68eSxcuJBHH32UuXPn0tzcvFf3M+5ru9NPP51HHnmEhoYGgPQ09RlnnJG+XWI8Hqe5uZmqqiq2bdtGQ0MDHR0d/PWvf93l+40YMQKAP/3pT+nyM888k9tvvz39unO0ffzxx7Nx40YeeOABLrroov52j4iI7AcK4256u5/x0qVLmTx5Mvfcc0+/72fc13ZHHnkk3/rWtzj11FOZMmUKN9xwAwC/+tWveOGFF5g8eTLTpk3j3Xffxev18p3vfIcZM2Zw5pln7vK9b7nlFubOncu0adPSU+AAN998M01NTRx11FFMmTKFF154Ib3u05/+NCeddFJ66lpERJxhrLWOvPH06dNt58lHnVasWMGkSZP2an+5OGZ8sDnnnHP48pe/zBlnnNFnnd7+TGpqapg1a9Z+bp2onweG+nlgqJ/BGPO6tXZ6b+s0Mj4Ibd++nQkTJhAIBHYZxCIiMjB0Atc+OhDvZ1xaWsqqVaucboaIiKQojPeR7mcsIiL7atBNUzt1DFt60p+FiMjAGFRh7Pf7aWhoUAgMAtZaGhoa8Pv9TjdFRCTvDapp6pEjR1JbW0tdXd0eb9ve3q7gyDG/38/IkSOdboaISN7rVxgbY2YDvwLcwJ3W2p90W+8D7gGmAQ3APGvtuj1tjNfrTV/GcU/V1NQwderUvdpWRETESbudpjbGuIHbgY8DRwAXGWOO6FbtCqDJWnsY8F/Af+a6oSIiIvmqP8eMZwCrrbVrrLURYCHQ/R6Cc4DOazA+CpxhdndbIxEREQH6F8YjgI0Zr2tTZb3WsdbGgGagIhcNFBERyXcDegKXMeZq4OrUyxZjzMoc7n4IUJ/D/Unf1NcDQ/08MNTPA0P9DKP7WtGfMN4EjMp4PTJV1ludWmOMBygheSJXFmvtAmBBP95zjxljlvZ1zU/JLfX1wFA/Dwz188BQP+9af6aplwDjjTFjjTEFwIXAk93qPAlcllr+N+B5qx8Li4iI9MtuR8bW2pgx5lrgGZI/bbrLWvuOMeb7wFJr7ZPA/wD3GmNWA40kA1tERET6oV/HjK21i4BF3cq+k7HcDszNbdP22H6Z/pZeqa8Hhvp5YKifB4b6eRccu5+xiIiIJA2qa1OLiIgcjPIijI0xs40xK40xq40xNzrdnnxkjBlljHnBGPOuMeYdY8x/ON2mfGaMcRtj/mWM+avTbclXxphSY8yjxpj3jDErjDEznW5TvjLGfDn1/8bbxpgHjTG6kUA3B3wY9/NynbLvYsBXrLVHACcAX1Q/71f/AaxwuhF57lfA09baicAU1N/7hTFmBHA9MN1aexTJE4F1km83B3wY07/Ldco+stZusda+kVreSfI/ru5XYpMcMMaMBD4B3Ol0W/KVMaYEOIXkL0Gw1kastdsdbVR+8wCB1HUogsBmh9sz6ORDGPfncp2SQ8aYMcBU4DWHm5Kvfgl8HUg43I58NhaoA+5OHQ640xgTcrpR+chauwn4GbAB2AI0W2v/z9lWDT75EMYygIwxhcBjwJestTucbk++McacA2yz1r7udFvynAc4FrjDWjsVaAV0vsl+YIwpIzlbORaoBkLGmM8426rBJx/CuD+X65QcMMZ4SQbx/dbax51uT546CTjPGLOO5CGX040x9znbpLxUC9Raaztndx4lGc6Sex8F1lpr66y1UeBx4ESH2zTo5EMY9+dynbKPUrfE/B9ghbX2F063J19Za79prR1prR1D8u/y89ZajSJyzFq7FdhojDk8VXQG8K6DTcpnG4ATjDHB1P8jZ6CT5XoY0Ls27Q99Xa7T4Wblo5OAS4HlxphlqbKbUldnEzkQXQfcn/oSvwaY73B78pK19jVjzKPAGyR/lfEvdDWuHnQFLhEREYflwzS1iIjIAU1hLCIi4jCFsYiIiMMUxiIiIg5TGIuIiDhMYSwiIuIwhbGIiIjDFMYiIiIO+/9/VJNm0KUekwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3454 - accuracy: 0.8772 - 337ms/epoch - 1ms/step\n",
      "\n",
      "Test accuracy: 0.8772000074386597\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning if any\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7030362e-08, 1.7360540e-09, 1.9982622e-09, 2.2075419e-09,\n",
       "       1.1619717e-08, 6.8660383e-03, 3.0194394e-07, 1.6523026e-02,\n",
       "       2.8199074e-07, 9.7661030e-01], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can read more on MNIST fashion example [here](https://www.tensorflow.org/tutorials/keras/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California House Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to build a regression model for Califronia house pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(5160, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.8765 - val_loss: 3.4932\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 2.1389 - val_loss: 0.4570\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6027 - val_loss: 706.8928\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.2320 - val_loss: 0.3775\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3973 - val_loss: 0.3753\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3896 - val_loss: 0.3723\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3888 - val_loss: 0.3722\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3838 - val_loss: 0.3638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3795 - val_loss: 0.3625\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3778 - val_loss: 0.3627\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3756 - val_loss: 0.3634\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3748 - val_loss: 0.3578\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3722 - val_loss: 0.3571\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3718 - val_loss: 0.3582\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3706 - val_loss: 0.3558\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3692 - val_loss: 0.3604\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3682 - val_loss: 0.3602\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3662 - val_loss: 0.3694\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.3563\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3660 - val_loss: 0.3587\n"
     ]
    }
   ],
   "source": [
    "# build a regression NN\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # output layer with 1 neuron and with None activation function because it's regression\n",
    "])\n",
    "\n",
    "# compile NN\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3739\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5506446],\n",
       "       [1.5555611],\n",
       "       [1.2865729]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. Loading the model is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if training lasts several hours? This is quite common, especially when training on large datasets.\n",
    "\n",
    "In this case, you should not only save your model at the end of training, but also save **checkpoints** at regular intervals during training, to avoid losing everything if your computer crashes.\n",
    "\n",
    "How can you tell the `fit()` method to save **checkpoints**? Use **callbacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method accepts a `callbacks` argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint` .\n",
    "\n",
    "In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a simple way to implement **early stopping**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.9862 - val_loss: 0.8386\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7876 - val_loss: 0.6902\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6942 - val_loss: 0.6427\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6443 - val_loss: 0.5875\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.6000 - val_loss: 0.5569\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5703 - val_loss: 0.5278\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5432 - val_loss: 0.5029\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5205 - val_loss: 0.4810\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5018 - val_loss: 0.4683\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4879 - val_loss: 0.4567\n"
     ]
    }
   ],
   "source": [
    "# train with callbacks and validation_data\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4763\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another way to implement **early stopping** is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the `patience` argument), and it will optionally roll back to the best model.\n",
    "\n",
    "> You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/ml/assignments/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4750 - val_loss: 0.4492\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4675 - val_loss: 0.4377\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4581 - val_loss: 0.4387\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4533 - val_loss: 0.4344\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4475 - val_loss: 0.4402\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4447 - val_loss: 0.4173\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4350 - val_loss: 0.4180\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4301 - val_loss: 0.4123\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4255 - val_loss: 0.4102\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4215 - val_loss: 0.4057\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4181 - val_loss: 0.4060\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4114 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4084 - val_loss: 0.3950\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4051 - val_loss: 0.3922\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4028 - val_loss: 0.3910\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4001 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3976 - val_loss: 0.3888\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3954 - val_loss: 0.3843\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3933 - val_loss: 0.3834\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3912 - val_loss: 0.3814\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3897 - val_loss: 0.3806\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3877 - val_loss: 0.3810\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3858 - val_loss: 0.3765\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3844 - val_loss: 0.3768\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3832 - val_loss: 0.3749\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3816 - val_loss: 0.3745\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3802 - val_loss: 0.3732\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3789 - val_loss: 0.3711\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3778 - val_loss: 0.3711\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3766 - val_loss: 0.3675\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3753 - val_loss: 0.3678\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3741 - val_loss: 0.3683\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3731 - val_loss: 0.3661\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3721 - val_loss: 0.3650\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3709 - val_loss: 0.3626\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3700 - val_loss: 0.3637\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3691 - val_loss: 0.3629\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3684 - val_loss: 0.3623\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3674 - val_loss: 0.3595\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3670 - val_loss: 0.3601\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3660 - val_loss: 0.3588\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3654 - val_loss: 0.3591\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3646 - val_loss: 0.3572\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3639 - val_loss: 0.3572\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3635 - val_loss: 0.3563\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3626 - val_loss: 0.3547\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3618 - val_loss: 0.3552\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3613 - val_loss: 0.3552\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3606 - val_loss: 0.3547\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3602 - val_loss: 0.3523\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3595 - val_loss: 0.3511\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3587 - val_loss: 0.3515\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3583 - val_loss: 0.3502\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3578 - val_loss: 0.3494\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3573 - val_loss: 0.3494\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3567 - val_loss: 0.3473\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3562 - val_loss: 0.3483\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3556 - val_loss: 0.3466\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3551 - val_loss: 0.3457\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3544 - val_loss: 0.3473\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3539 - val_loss: 0.3464\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3533 - val_loss: 0.3453\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3527 - val_loss: 0.3434\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3522 - val_loss: 0.3442\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3517 - val_loss: 0.3416\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3510 - val_loss: 0.3430\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3506 - val_loss: 0.3410\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3501 - val_loss: 0.3419\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3496 - val_loss: 0.3421\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3492 - val_loss: 0.3386\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3488 - val_loss: 0.3397\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3485 - val_loss: 0.3384\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3479 - val_loss: 0.3386\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3471 - val_loss: 0.3371\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3469 - val_loss: 0.3383\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3462 - val_loss: 0.3368\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3461 - val_loss: 0.3366\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3455 - val_loss: 0.3349\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3449 - val_loss: 0.3365\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3444 - val_loss: 0.3366\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3442 - val_loss: 0.3350\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3437 - val_loss: 0.3371\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3433 - val_loss: 0.3343\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3431 - val_loss: 0.3344\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3424 - val_loss: 0.3312\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3420 - val_loss: 0.3336\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3413 - val_loss: 0.3315\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3415 - val_loss: 0.3328\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3407 - val_loss: 0.3299\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3402 - val_loss: 0.3314\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3397 - val_loss: 0.3297\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3392 - val_loss: 0.3311\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3386 - val_loss: 0.3306\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3384 - val_loss: 0.3290\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3382 - val_loss: 0.3303\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3377 - val_loss: 0.3264\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3371 - val_loss: 0.3282\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3366 - val_loss: 0.3266\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3361 - val_loss: 0.3262\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3432\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect over‐fitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/363 [============================>.] - ETA: 0s - loss: 0.3357\n",
      "val/train: 0.97\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3358 - val_loss: 0.3258\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat feature of Tensorflow and Keras is visulaization through Tensorboard. The following code shows how you can visualize your training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3353 - val_loss: 0.3266\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3259\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.3266\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3258\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3335 - val_loss: 0.3243\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3260\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3330 - val_loss: 0.3224\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3326 - val_loss: 0.3251\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3238\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3223\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3313 - val_loss: 0.3224\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3308 - val_loss: 0.3219\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3305 - val_loss: 0.3212\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3300 - val_loss: 0.3205\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3295 - val_loss: 0.3194\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.3227\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3193\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3230\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3285 - val_loss: 0.3189\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3284 - val_loss: 0.3253\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3193\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3271\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3283 - val_loss: 0.3185\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3264\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3165\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3279\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3199\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3298 - val_loss: 0.3364\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3295 - val_loss: 0.3255\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3507\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard Visualization\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, run the following command at the root of the project directory where `my_logs` has been saved (or from anywhere else, as long as you point to the appropriate log directory):\n",
    "\n",
    "> `$ tensorboard --logdir=./my_logs --port=6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And finally, once the server is up, you can open a web browser and go to:\n",
    "\n",
    "> http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-1 has 10 points**.\n",
    "\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "- Imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k and so on.\n",
    "\n",
    "- How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k.\n",
    "\n",
    "**Hint**: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data with at least 6 data points for x and y\n",
    "xs = np.array([0, 1, 2, 3, 4, 5, 6], dtype=float)\n",
    "ys = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with one layer and one neuron\n",
    "exercise_1_layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "exercise_1_model = tf.keras.Sequential([exercise_1_layer_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for regression\n",
    "exercise_1_model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 3.1569\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7158\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9559\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5550\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3432\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2310\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1713\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1393\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1218\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1121\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1064\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1028\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1004\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0986\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0971\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0958\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0946\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0935\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0923\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0913\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0902\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0891\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0881\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0871\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0861\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0851\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0841\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0831\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0821\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0812\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0802\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0793\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0784\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0775\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0765\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0757\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0748\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0739\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0730\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0722\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0714\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0705\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0697\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0689\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0681\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0673\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0665\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0657\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0650\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0642\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0635\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0627\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0620\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0613\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0606\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0599\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0592\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0585\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0578\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0571\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0565\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0558\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0552\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0545\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0539\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0533\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0526\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0520\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0514\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0508\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0502\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0496\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0491\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0485\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0479\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0474\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0468\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0463\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0457\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0452\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0447\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0442\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0436\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0431\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0426\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0421\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0416\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0412\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0407\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0402\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0397\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0393\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0388\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0384\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0379\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0375\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0370\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0366\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0362\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0358\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0354\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0349\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0345\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0341\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0337\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0333\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0330\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0326\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0322\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0318\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0314\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0311\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0307\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0304\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0300\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0297\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0293\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0290\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0286\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0283\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0280\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0276\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0273\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0270\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0267\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0264\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0261\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0258\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0255\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0252\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0249\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0246\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0243\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0240\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0237\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0235\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0232\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0229\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0227\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0224\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0221\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0219\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0216\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0214\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0211\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0209\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0206\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0204\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0202\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0199\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0197\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0195\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0192\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0188\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0186\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0184\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0179\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0177\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0175\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0173\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0171\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0167\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0165\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0163\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0161\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0159\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0158\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0156\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0154\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0152\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0150\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0149\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0147\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0145\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0144\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0142\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0140\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0139\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0137\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0135\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0134\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0132\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0131\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0129\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0128\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0126\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0125\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0123\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0122\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0120\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0119\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0118\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0116\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0114\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0112\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0111\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0110\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0108\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0107\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0106\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0105\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0103\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0102\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0101\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0100\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0099\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0098\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0096\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0095\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0094\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0093\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0091\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0089\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0088\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0087\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0086\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0085\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0084\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0083\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0082\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0081\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0080\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0079\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0078\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0077\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0076\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0075\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0075\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0074\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0073\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0071\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0070\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0069\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0068\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0067\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0066\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0066\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0065\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0064\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0063\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0063\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0062\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0061\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0060\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0060\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0059\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0058\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0057\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0056\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0056\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0054\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0054\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0053\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0052\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0051\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0051\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0049\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0047\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0046\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0046\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0045\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0045\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0044\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0043\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0043\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0042\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0042\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0042\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0041\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0040\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0039\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0039\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0038\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0037\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0037\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0036\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0036\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0035\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0035\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0034\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0034\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0034\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0033\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0032\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0032\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0032\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0031\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0031\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0030\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0030\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0030\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0029\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0029\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0028\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0028\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0027\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0027\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0027\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0026\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0026\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0026\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0025\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0025\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0025\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0024\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0024\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0024\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0023\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0023\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0023\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0022\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0022\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0021\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0021\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0020\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0020\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0019\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0019\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0019\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0018\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0018\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0017\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0016\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0016\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0016\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0016\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0015\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0015\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0015\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0015\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0014\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0014\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0014\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0014\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0013\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0013\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0013\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0012\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0012\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0012\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0012\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0011\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0011\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0011\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0011\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0010\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0010\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0010\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0010\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.9501e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8343e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.7199e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.6067e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.4949e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3844e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.2752e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1673e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.0606e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.9551e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.8509e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.7479e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.6461e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5455e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.4460e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.3478e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.2506e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1546e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.0597e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9659e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8732e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7816e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.6910e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6015e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.5130e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.4256e-04\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.3392e-04\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2538e-04\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.1693e-04\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.0859e-04\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.0034e-04\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.9219e-04\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8414e-04\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7618e-04\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6831e-04\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.6053e-04\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.5284e-04\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4524e-04\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.3773e-04\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3031e-04\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2298e-04\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1573e-04\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0856e-04\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0148e-04\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9448e-04\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8756e-04\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8072e-04\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7396e-04\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6728e-04\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.6068e-04\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.5416e-04\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4771e-04\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4133e-04\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3503e-04\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.2881e-04\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2265e-04\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1657e-04\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.1056e-04\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.0462e-04\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9874e-04\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9294e-04\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.8720e-04\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8153e-04\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7593e-04\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.7039e-04\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.6492e-04\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5951e-04\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5416e-04\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4887e-04\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.4365e-04\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3849e-04\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3338e-04\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.2834e-04\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2335e-04\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1843e-04\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1356e-04\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0874e-04\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0399e-04\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9929e-04\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9464e-04\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9005e-04\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.8551e-04\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8102e-04\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7659e-04\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7221e-04\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.6787e-04\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.6359e-04\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5936e-04\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.5518e-04\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5104e-04\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4696e-04\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4292e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3893e-04\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3499e-04\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3109e-04\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.2723e-04\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2343e-04\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1966e-04\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1594e-04\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1227e-04\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0863e-04\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.0504e-04\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0149e-04\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.9798e-04\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9451e-04\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.9109e-04\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8770e-04\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8435e-04\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.8104e-04\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7777e-04\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7454e-04\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7134e-04\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6818e-04\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6506e-04\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6198e-04\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5893e-04\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5592e-04\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5294e-04\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4999e-04\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4709e-04\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4421e-04\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4137e-04\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3856e-04\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3578e-04\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3304e-04\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3033e-04\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2765e-04\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2500e-04\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2238e-04\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1979e-04\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1723e-04\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1470e-04\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1220e-04\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0974e-04\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0730e-04\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0488e-04\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0250e-04\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0014e-04\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9781e-04\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9551e-04\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9323e-04\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9099e-04\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8876e-04\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8657e-04\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8440e-04\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8225e-04\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8013e-04\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7803e-04\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7596e-04\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7391e-04\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7189e-04\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6989e-04\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6791e-04\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6596e-04\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6403e-04\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6212e-04\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6023e-04\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5837e-04\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5652e-04\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5470e-04\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5290e-04\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5112e-04\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4936e-04\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4762e-04\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4591e-04\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4421e-04\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4253e-04\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4087e-04\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3923e-04\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3761e-04\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3601e-04\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3443e-04\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3286e-04\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3131e-04\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2979e-04\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2828e-04\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2678e-04\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2531e-04\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2385e-04\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2241e-04\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2098e-04\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1958e-04\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1818e-04\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1681e-04\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1545e-04\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1411e-04\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1278e-04\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1146e-04\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1017e-04\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0889e-04\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0762e-04\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0637e-04\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0513e-04\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0390e-04\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0270e-04\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0150e-04\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0032e-04\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.9152e-05\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.7998e-05\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.6858e-05\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5730e-05\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4616e-05\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 9.3515e-05\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.2427e-05\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.1351e-05\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.0288e-05\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.9237e-05\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.8199e-05\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.7173e-05\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.6158e-05\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.5155e-05\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.4164e-05\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.3185e-05\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.2217e-05\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.1260e-05\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.0314e-05\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9380e-05\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.8456e-05\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7543e-05\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.6640e-05\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.5749e-05\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.4867e-05\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3995e-05\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3134e-05\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.2283e-05\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1442e-05\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0610e-05\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9789e-05\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8977e-05\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.8174e-05\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7381e-05\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.6597e-05\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5821e-05\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5055e-05\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4298e-05\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3550e-05\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2810e-05\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2079e-05\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1357e-05\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0643e-05\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.9937e-05\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.9240e-05\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8550e-05\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.7869e-05\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.7195e-05\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6529e-05\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.5872e-05\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.5222e-05\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4579e-05\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3944e-05\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3316e-05\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.2695e-05\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2082e-05\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.1477e-05\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.0877e-05\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.0285e-05\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.9700e-05\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9122e-05\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8550e-05\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7985e-05\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.7426e-05\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6874e-05\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.6329e-05\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.5790e-05\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5257e-05\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4730e-05\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4209e-05\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3695e-05\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3187e-05\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.2684e-05\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2187e-05\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1696e-05\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1211e-05\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0731e-05\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0257e-05\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9788e-05\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9326e-05\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.8867e-05\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8415e-05\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7968e-05\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.7526e-05\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7089e-05\n",
      "Epoch 688/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6658e-05\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.6231e-05\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5810e-05\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5393e-05\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4981e-05\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4574e-05\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4172e-05\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.3774e-05\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3381e-05\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2993e-05\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2609e-05\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2229e-05\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1854e-05\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.1483e-05\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1117e-05\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.0755e-05\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0396e-05\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0043e-05\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9693e-05\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9348e-05\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9006e-05\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8669e-05\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.8335e-05\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.8005e-05\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7679e-05\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7357e-05\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.7039e-05\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.6724e-05\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6413e-05\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.6106e-05\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5802e-05\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5501e-05\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5205e-05\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4911e-05\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4621e-05\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4335e-05\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4052e-05\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3772e-05\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3495e-05\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3222e-05\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2951e-05\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2685e-05\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2421e-05\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2160e-05\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1902e-05\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1647e-05\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1395e-05\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1146e-05\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0900e-05\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0657e-05\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0416e-05\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0179e-05\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9944e-05\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9712e-05\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9483e-05\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9256e-05\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9032e-05\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8810e-05\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8592e-05\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8375e-05\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8161e-05\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7950e-05\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7741e-05\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7535e-05\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7331e-05\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7129e-05\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6930e-05\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6732e-05\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6538e-05\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6345e-05\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6155e-05\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5967e-05\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5781e-05\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5598e-05\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5416e-05\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5237e-05\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5059e-05\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4884e-05\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4711e-05\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4540e-05\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4371e-05\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4203e-05\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4038e-05\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3875e-05\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3713e-05\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3554e-05\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3396e-05\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3240e-05\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3086e-05\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2934e-05\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2783e-05\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2634e-05\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2487e-05\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2342e-05\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2198e-05\n",
      "Epoch 783/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2056e-05\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1916e-05\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1777e-05\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1640e-05\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1505e-05\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1371e-05\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1238e-05\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1108e-05\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0978e-05\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0851e-05\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0724e-05\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0600e-05\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0476e-05\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0354e-05\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0234e-05\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0115e-05\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.9971e-06\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.8807e-06\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.7657e-06\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.6519e-06\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5398e-06\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.4286e-06\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3188e-06\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.2104e-06\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.1034e-06\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.9975e-06\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8926e-06\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.7891e-06\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.6870e-06\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.5858e-06\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.4857e-06\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.3870e-06\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.2895e-06\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1930e-06\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.0975e-06\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0032e-06\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9102e-06\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.8182e-06\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7272e-06\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.6372e-06\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5483e-06\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.4605e-06\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.3738e-06\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.2877e-06\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2030e-06\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1192e-06\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.0364e-06\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9543e-06\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.8737e-06\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7935e-06\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.7144e-06\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6363e-06\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.5592e-06\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.4828e-06\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.4073e-06\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3329e-06\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2591e-06\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.1862e-06\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.1143e-06\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0432e-06\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.9727e-06\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.9034e-06\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.8347e-06\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.7668e-06\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.6998e-06\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6334e-06\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.5679e-06\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5031e-06\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.4390e-06\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3758e-06\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.3132e-06\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2513e-06\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.1903e-06\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1298e-06\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.0702e-06\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0111e-06\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.9529e-06\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8952e-06\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8382e-06\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.7819e-06\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7262e-06\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6712e-06\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.6169e-06\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.5630e-06\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5101e-06\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4575e-06\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.4055e-06\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3543e-06\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3037e-06\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2535e-06\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.2041e-06\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1551e-06\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1069e-06\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0590e-06\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.0117e-06\n",
      "Epoch 878/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9650e-06\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9189e-06\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8733e-06\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.8282e-06\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7837e-06\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7397e-06\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6962e-06\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.6531e-06\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6106e-06\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5687e-06\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.5272e-06\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4860e-06\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.4455e-06\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.4054e-06\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3657e-06\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3266e-06\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2878e-06\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2496e-06\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2119e-06\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.1744e-06\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1374e-06\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.1011e-06\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0649e-06\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0292e-06\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9939e-06\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.9591e-06\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9245e-06\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8906e-06\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.8570e-06\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8237e-06\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7909e-06\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7584e-06\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7262e-06\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6945e-06\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6633e-06\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6323e-06\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.6016e-06\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5713e-06\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5413e-06\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.5117e-06\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4825e-06\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4537e-06\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4251e-06\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3968e-06\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3690e-06\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3415e-06\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3141e-06\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2872e-06\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2606e-06\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2343e-06\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2083e-06\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1827e-06\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1572e-06\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1322e-06\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1073e-06\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0828e-06\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0586e-06\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0346e-06\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0110e-06\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9876e-06\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9644e-06\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9416e-06\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9190e-06\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8966e-06\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8745e-06\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8528e-06\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.8312e-06\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8099e-06\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7888e-06\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7680e-06\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7474e-06\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7271e-06\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7070e-06\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6871e-06\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6675e-06\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6481e-06\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6288e-06\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6099e-06\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5912e-06\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5727e-06\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5544e-06\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5363e-06\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5185e-06\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5007e-06\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4833e-06\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4660e-06\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4490e-06\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4322e-06\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4154e-06\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3989e-06\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3827e-06\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3666e-06\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3507e-06\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3350e-06\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3195e-06\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3041e-06\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2889e-06\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2739e-06\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2590e-06\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2444e-06\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2299e-06\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2156e-06\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2015e-06\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1875e-06\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1737e-06\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1600e-06\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1465e-06\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1332e-06\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1200e-06\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1070e-06\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0941e-06\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0813e-06\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0688e-06\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0563e-06\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0440e-06\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0319e-06\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0198e-06\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0080e-06\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.9629e-07\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.8470e-07\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.7323e-07\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.6189e-07\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.5079e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8241644af0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 1000 epochs\n",
    "exercise_1_model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400113.96408081]]\n"
     ]
    }
   ],
   "source": [
    "# predict the price for 7-bedroom house price\n",
    "print(exercise_1_model.predict([7.0]) * 100000) # Convert answer to hundreds of thousands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-2 has 20 points**.\n",
    "\n",
    "In this notebook you learned how to do classification using Fashion MNIST, a data set containing items of clothing, and a similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy using `callbacks`.\n",
    "\n",
    "- **Requirements**:\n",
    "1. It should succeed in less than 10 epochs.\n",
    "2. When it reaches 99% or greater it should print out the string `\"Reached 99% accuracy so cancelling training!\"` as specified in the `myCallback` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.99):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load data\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model - be careful about the activation functions of the hidden layer and output layer\n",
    "exercise_2_model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')]) # the output layer has 10 neurons and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for multi-class classification, metrics should be 'accuracy'\n",
    "exercise_2_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2583 - accuracy: 0.9259\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1119 - accuracy: 0.9660\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0775 - accuracy: 0.9760\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0580 - accuracy: 0.9825\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0459 - accuracy: 0.9857\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0358 - accuracy: 0.9889\n",
      "Epoch 7/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9911\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0286 - accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f824165f370>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 10 epochs (will stop earlier) and callbacks\n",
    "# Note: Your output should include the message: \"Reached 99% accuracy so cancelling training!\"\n",
    "# The output should also include:\n",
    "# <tensorflow.python.keras.callbacks.History at MEMORY_ADDRESS> \n",
    "# create checkpoint\n",
    "exercise_2_history = exercise_2_model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "exercise_2_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] - [Tensorflow Website](https://www.tensorflow.org/)\n",
    "- [2] - [Tensorflow Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [3] - [Hands-On ML Textbook 2nd Edition](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [4] - [DeepLearning.AI TensorFlow Developer Professional Certificate - Course-1](https://www.coursera.org/professional-certificates/tensorflow-in-practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-tf-notebook.ipynb```. Submit the file using the ```tf-notebook``` link on Blackboard.\n",
    "\n",
    "- tf-notebook has a total of 30 points which will be counted towards the \"Assignment\" section of your final grade.\n",
    "\n",
    "- **RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * verification of correct installation of Tensorflow\n",
    "  * error-free running of all the cells - all outputs and plots must be included - any missing output would cause the notebook to get ZERO!\n",
    "  * correct answers to the exercises - Exercise-1 [10 points], Exercise-2 [20 points]\n",
    "  \n",
    "<font color=red><b>Due Date: Tuesday April 19th, 11:59PM</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
